{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Faxe Flow based data-collector and time-centric data-processor. Rest Api FAXE can be managed via its rest api . General Data in faxe In faxe we deal with data_points and data_batches . Every data_point consists of a ts field, fields and tags . The value of the ts field is always: unix-timestamp in millisecond precision without a timezone . fields and tags are essentially key-value maps . Valid data-types for field and tag values are: string, integer, float, key-value map (also deeply nested) and lists . The only valid data-type for field and tag keys is string . A data_batch consists of a list of data_points ordered by timestamp. Most faxe nodes can deal with both points and batches. Value referencing As field and tag values can be deeply nested maps and lists, it is possible to use a JSON-path like syntax to declare and reference these values: Valid examples: averages axis.z.cur value.sub[2].data averages.emitted[5]","title":"Faxe"},{"location":"index.html#faxe","text":"Flow based data-collector and time-centric data-processor.","title":"Faxe"},{"location":"index.html#rest-api","text":"FAXE can be managed via its rest api .","title":"Rest Api"},{"location":"index.html#general","text":"","title":"General"},{"location":"index.html#data-in-faxe","text":"In faxe we deal with data_points and data_batches . Every data_point consists of a ts field, fields and tags . The value of the ts field is always: unix-timestamp in millisecond precision without a timezone . fields and tags are essentially key-value maps . Valid data-types for field and tag values are: string, integer, float, key-value map (also deeply nested) and lists . The only valid data-type for field and tag keys is string . A data_batch consists of a list of data_points ordered by timestamp. Most faxe nodes can deal with both points and batches.","title":"Data in faxe"},{"location":"index.html#value-referencing","text":"As field and tag values can be deeply nested maps and lists, it is possible to use a JSON-path like syntax to declare and reference these values: Valid examples: averages axis.z.cur value.sub[2].data averages.emitted[5]","title":"Value referencing"},{"location":"dfs_examples/consume_data_rewrite_republish.html","text":"Data cleaning and publishing Consume data from an MQTT-Broker and do some cleaning, at the end republish this data. def topic_in = 'ttgw/grip/rovolutionwels/reasoning/schedulers_ol_log' def topic_out = 'ttgw/data/grip/rovolutionwels/reasoning/schedulers_ol_log' def host = '10.14.204.3' | mqtt_subscribe() . host ( host ) . topic ( topic_in ) . dt_field ( 'UTC-Time' ) . dt_format ( 'float_micro' ) %% here is were we clean data | eval() . lambdas ( lambda : int ( \"sku_length\" * 1000 ), lambda : int ( \"sku_width\" * 1000 ), lambda : int ( \"source_lc_quantity\" ), lambda : int ( \"pcs_lost\" ) ) %% overwrite the original fields . as ( 'sku_length' , 'sku_width' , 'source_lc_quantity' , 'pcs_lost' ) | delete() . fields ( 'UTC-Time' ) % publish the resulting message | mqtt_publish() . host ( host ) . qos ( 1 ) . topic ( topic_out ) . retained ()","title":"Consume data rewrite republish"},{"location":"dfs_examples/consume_data_rewrite_republish.html#data-cleaning-and-publishing","text":"Consume data from an MQTT-Broker and do some cleaning, at the end republish this data. def topic_in = 'ttgw/grip/rovolutionwels/reasoning/schedulers_ol_log' def topic_out = 'ttgw/data/grip/rovolutionwels/reasoning/schedulers_ol_log' def host = '10.14.204.3' | mqtt_subscribe() . host ( host ) . topic ( topic_in ) . dt_field ( 'UTC-Time' ) . dt_format ( 'float_micro' ) %% here is were we clean data | eval() . lambdas ( lambda : int ( \"sku_length\" * 1000 ), lambda : int ( \"sku_width\" * 1000 ), lambda : int ( \"source_lc_quantity\" ), lambda : int ( \"pcs_lost\" ) ) %% overwrite the original fields . as ( 'sku_length' , 'sku_width' , 'source_lc_quantity' , 'pcs_lost' ) | delete() . fields ( 'UTC-Time' ) % publish the resulting message | mqtt_publish() . host ( host ) . qos ( 1 ) . topic ( topic_out ) . retained ()","title":"Data cleaning and publishing"},{"location":"dfs_examples/python_double.html","text":"Custom python node Using a custom python node called double to double values of a data_batch. Here data is produced every 2s, then accumulated to a data_batch of length 6, the result gets then forwarded to our custom python node, which doubles all values of the field val . dfs | value_emitter() . every ( 2s ) . type ( point ) | win_event() . every ( 6 ) @ double () . field ( 'val' ) . as ( 'double_val' ) | debug() python from faxe import Faxe class Double (Faxe): @staticmethod def options (): opts = [ ( b'field' , b'string' ), ( b'as' , b'string' ) ] return opts def init (self, args): self . fieldname = args[ b'field' ] self . asfieldname = args[ b'as' ] def handle_point (self, point_data): self . emit(self . calc(point_data)) def handle_batch (self, batch_data): out_list = list() for point in batch_data: out_list . append(self . calc(point)) self . emit(out_list) def calc (self, point_dict): point_dict[self . asfieldname] = point_dict[self . fieldname] * 2 return point_dict","title":"Python double"},{"location":"dfs_examples/python_double.html#custom-python-node","text":"Using a custom python node called double to double values of a data_batch. Here data is produced every 2s, then accumulated to a data_batch of length 6, the result gets then forwarded to our custom python node, which doubles all values of the field val .","title":"Custom python node"},{"location":"dfs_examples/python_double.html#dfs","text":"| value_emitter() . every ( 2s ) . type ( point ) | win_event() . every ( 6 ) @ double () . field ( 'val' ) . as ( 'double_val' ) | debug()","title":"dfs"},{"location":"dfs_examples/python_double.html#python","text":"from faxe import Faxe class Double (Faxe): @staticmethod def options (): opts = [ ( b'field' , b'string' ), ( b'as' , b'string' ) ] return opts def init (self, args): self . fieldname = args[ b'field' ] self . asfieldname = args[ b'as' ] def handle_point (self, point_data): self . emit(self . calc(point_data)) def handle_batch (self, batch_data): out_list = list() for point in batch_data: out_list . append(self . calc(point)) self . emit(out_list) def calc (self, point_dict): point_dict[self . asfieldname] = point_dict[self . fieldname] * 2 return point_dict","title":"python"},{"location":"dfs_examples/read_modbus_publish_mqtt.html","text":"Modbus to MQTT In this example we write a simple DFS which reads energy data from a modbus-tcp device periodically and publishes to an mqtt broker. def device_id = 255 def modbus_ip = '127.0.0.1' def mqtt_broker = '10.14.204.3' | modbus() . ip ( '127.0.0.1' ) %% not the default port here . port ( 8899 ) . device ( device_id ) %% we read the values every second . every ( 1s ) %% we read 3 values . function ( 'coils' , 'hregs' , 'iregs' ) %% start addresses . from ( 2127 , 3008 , 104 ) %% amount of data for each value . count ( 1 , 2 , 2 ) %% we want these resulting fieldnames . as ( 'ActiveEnergyConsumption' , 'MaximalCurrentValue' , 'BlindEnergyDelivered' ) %% add some default values to each message | default() . fields ( 'id' , 'vs' , 'df' ) . field_values ( 'my_id_string' , 1 , '01.010' ) %% publish to mqtt broker | mqtt_publish() . host ( mqtt_broker ) . port ( 1883 ) . qos ( 1 ) . topic ( 'ttopic/energy' ) . retained ()","title":"Read modbus publish mqtt"},{"location":"dfs_examples/read_modbus_publish_mqtt.html#modbus-to-mqtt","text":"In this example we write a simple DFS which reads energy data from a modbus-tcp device periodically and publishes to an mqtt broker. def device_id = 255 def modbus_ip = '127.0.0.1' def mqtt_broker = '10.14.204.3' | modbus() . ip ( '127.0.0.1' ) %% not the default port here . port ( 8899 ) . device ( device_id ) %% we read the values every second . every ( 1s ) %% we read 3 values . function ( 'coils' , 'hregs' , 'iregs' ) %% start addresses . from ( 2127 , 3008 , 104 ) %% amount of data for each value . count ( 1 , 2 , 2 ) %% we want these resulting fieldnames . as ( 'ActiveEnergyConsumption' , 'MaximalCurrentValue' , 'BlindEnergyDelivered' ) %% add some default values to each message | default() . fields ( 'id' , 'vs' , 'df' ) . field_values ( 'my_id_string' , 1 , '01.010' ) %% publish to mqtt broker | mqtt_publish() . host ( mqtt_broker ) . port ( 1883 ) . qos ( 1 ) . topic ( 'ttopic/energy' ) . retained ()","title":"Modbus to MQTT"},{"location":"dfs_script_language/index.html","text":"Introducing the DFS Script Language Faxe uses a DSL called dfs (Dataflow Scripting Language). Dfs is heavily influenced by InfluxData's TICKScript , in fact faxe started out as a clone of Kapacitor. To get a basic understanding of dfs, you can therefore read Introducing the TICKscript language . Some notable differences between TICKScript and dfs include: dfs uses the def keyword for declarations for comments the % sign is used in dfs there are no top-level stream or batch nodes lambda expression use different functions regular expressions start and end with '?' There is more, we will get to that ... In general dfs is used to build up DAGs (Directed Acyclic Graph) of computing nodes via a script language. While reading TICKscript syntax will help you get more understanding of dfs , here is also were the differences between TICKScript and dfs start to get bigger (tough not so much in syntax, so reading is recommended). After that, lets dive right in and override some details you just read about TICKScript: DFS Keywords Word Usage true boolean true false boolean false TRUE boolean true FALSE boolean false lambda: used to denote lambda expression def starts a variable declaration Operators Operator Usage + addition operator - substraction operator / division operator * multiplication operator AND and OR or < less than > greater than =< less than or equal <= less than or equal => greater or equal >= greater or equal == equal != Not equal /= Not equal ! Logical Not rem remainder div integer division These operators are mainly used in Lambda expressions in faxe. Chaining operators Operator Usage Example | Used to declare a new node instance and chains it to the node above it (if any) |some_node() |debug() . Declares a property (or parameter) call, setting or changing an internal param in the node to which it belongs |log() .file('log1.txt') @ Declares a user defined node written in python. Same as |, but for user defined nodes |some_node() ... @mynode() Variables and literals Variables are declared using the keyword def at the start of a declaration. Variables are immutable and cannot be reassigned new values later on in the script, though they can be used in other declarations and can be passed into functions, property calls and text-templates. Variable declarations def string = 'this is a string !' def text = <<< this is a text with some weird chars :// %& >>> def func = lambda : \"value\" / 3 def meas = 4.44 % A lambda expression as literal def func2 = lambda : int ( meas / 13 ) def an_int = 32342 def a_float = 2131.342 % a chain can also be bound to a declaration def in1 = | mqtt_subscribe() . host ( '127.0.0.1' ) . topic ( 'some/topic' ) % it can then be used like so in1 | debug() Datatypes DFS recognizes six basic types, the type of the literal will be interpreted from its declaration. Type name Description Examples string String type. Single quotes are used for string, string can also be multiline 'this_is_a_string' binary Same as 'string', internally faxe does not have a string type, all strings a binaries 'this_is_a_binary' text Text type. Mostly used where strings are used <<< SELECT MEAN(obj['current']) FROM mytable >>> integer Integer type. Arbitrarily big ints are allowed 123456789987654321, 55 float Floating point number. May be arbitrarily big 12.343422023, 5.6 double Same as float 12.343422023, 5.6 duration A duration literal. See section below. 34s, 500ms, 2d lambda A lambda expression. See extra section in this documentation lambda: str_downcase('BIG') Duration literals Duration literals define a span of time. A duration literal is comprised of two parts: an integer and a duration unit. It is essentially an integer terminated by one or a pair of reserved characters, which represent a unit of time. The following table presents the time units used in declaring duration types. Unit Meaning ms millisecond s second m minute h hour d day w week Internally all time and duration related values are converted to milliseconds in faxe. Examples def span = 10s def frequency = 10m def short = 50ms | win_time() . period ( 1h ) . every ( 30m ) Text templates {{ variable_name }} def this_portion = 'it' def text_template = <<< Some text where {{this_portion}} will get replaced >>> In the above example, after compilation of the dfs script the variable text_template will hold the following value: Some text where it will get replaced Text templates can be used in variable declarations like in the above example, they can be used in node-parameter and option-parameter calls. While the above example seems to be useless, when used in template scripts they can be very powerful. The variable this_portion could be overwritten with a new value for every instantiation of a template script. There is another version of text-templating which uses a value inside the current data_point, that can be used with some nodes in faxe: {{ \"value_name\" }} | email() . body ( <<< No data since {{ datetime }} on topic 'ttgw/energy' , last value was {{ val }}. >>> ) Here the values for datetime and val will be taken from the current data_point in the email node.","title":"Introducing the DFS Script Language"},{"location":"dfs_script_language/index.html#introducing-the-dfs-script-language","text":"Faxe uses a DSL called dfs (Dataflow Scripting Language). Dfs is heavily influenced by InfluxData's TICKScript , in fact faxe started out as a clone of Kapacitor. To get a basic understanding of dfs, you can therefore read Introducing the TICKscript language . Some notable differences between TICKScript and dfs include: dfs uses the def keyword for declarations for comments the % sign is used in dfs there are no top-level stream or batch nodes lambda expression use different functions regular expressions start and end with '?' There is more, we will get to that ... In general dfs is used to build up DAGs (Directed Acyclic Graph) of computing nodes via a script language. While reading TICKscript syntax will help you get more understanding of dfs , here is also were the differences between TICKScript and dfs start to get bigger (tough not so much in syntax, so reading is recommended). After that, lets dive right in and override some details you just read about TICKScript:","title":"Introducing the DFS Script Language"},{"location":"dfs_script_language/index.html#dfs","text":"","title":"DFS"},{"location":"dfs_script_language/index.html#keywords","text":"Word Usage true boolean true false boolean false TRUE boolean true FALSE boolean false lambda: used to denote lambda expression def starts a variable declaration","title":"Keywords"},{"location":"dfs_script_language/index.html#operators","text":"Operator Usage + addition operator - substraction operator / division operator * multiplication operator AND and OR or < less than > greater than =< less than or equal <= less than or equal => greater or equal >= greater or equal == equal != Not equal /= Not equal ! Logical Not rem remainder div integer division These operators are mainly used in Lambda expressions in faxe.","title":"Operators"},{"location":"dfs_script_language/index.html#chaining-operators","text":"Operator Usage Example | Used to declare a new node instance and chains it to the node above it (if any) |some_node() |debug() . Declares a property (or parameter) call, setting or changing an internal param in the node to which it belongs |log() .file('log1.txt') @ Declares a user defined node written in python. Same as |, but for user defined nodes |some_node() ... @mynode()","title":"Chaining operators"},{"location":"dfs_script_language/index.html#variables-and-literals","text":"Variables are declared using the keyword def at the start of a declaration. Variables are immutable and cannot be reassigned new values later on in the script, though they can be used in other declarations and can be passed into functions, property calls and text-templates.","title":"Variables and literals"},{"location":"dfs_script_language/index.html#variable-declarations","text":"def string = 'this is a string !' def text = <<< this is a text with some weird chars :// %& >>> def func = lambda : \"value\" / 3 def meas = 4.44 % A lambda expression as literal def func2 = lambda : int ( meas / 13 ) def an_int = 32342 def a_float = 2131.342 % a chain can also be bound to a declaration def in1 = | mqtt_subscribe() . host ( '127.0.0.1' ) . topic ( 'some/topic' ) % it can then be used like so in1 | debug()","title":"Variable declarations"},{"location":"dfs_script_language/index.html#datatypes","text":"DFS recognizes six basic types, the type of the literal will be interpreted from its declaration. Type name Description Examples string String type. Single quotes are used for string, string can also be multiline 'this_is_a_string' binary Same as 'string', internally faxe does not have a string type, all strings a binaries 'this_is_a_binary' text Text type. Mostly used where strings are used <<< SELECT MEAN(obj['current']) FROM mytable >>> integer Integer type. Arbitrarily big ints are allowed 123456789987654321, 55 float Floating point number. May be arbitrarily big 12.343422023, 5.6 double Same as float 12.343422023, 5.6 duration A duration literal. See section below. 34s, 500ms, 2d lambda A lambda expression. See extra section in this documentation lambda: str_downcase('BIG')","title":"Datatypes"},{"location":"dfs_script_language/index.html#duration-literals","text":"Duration literals define a span of time. A duration literal is comprised of two parts: an integer and a duration unit. It is essentially an integer terminated by one or a pair of reserved characters, which represent a unit of time. The following table presents the time units used in declaring duration types. Unit Meaning ms millisecond s second m minute h hour d day w week Internally all time and duration related values are converted to milliseconds in faxe.","title":"Duration literals"},{"location":"dfs_script_language/index.html#examples","text":"def span = 10s def frequency = 10m def short = 50ms | win_time() . period ( 1h ) . every ( 30m )","title":"Examples"},{"location":"dfs_script_language/index.html#text-templates","text":"{{ variable_name }} def this_portion = 'it' def text_template = <<< Some text where {{this_portion}} will get replaced >>> In the above example, after compilation of the dfs script the variable text_template will hold the following value: Some text where it will get replaced Text templates can be used in variable declarations like in the above example, they can be used in node-parameter and option-parameter calls. While the above example seems to be useless, when used in template scripts they can be very powerful. The variable this_portion could be overwritten with a new value for every instantiation of a template script. There is another version of text-templating which uses a value inside the current data_point, that can be used with some nodes in faxe: {{ \"value_name\" }} | email() . body ( <<< No data since {{ datetime }} on topic 'ttgw/energy' , last value was {{ val }}. >>> ) Here the values for datetime and val will be taken from the current data_point in the email node.","title":"Text templates"},{"location":"dfs_script_language/lambda_expressions.html","text":"Lambda expressions Overview DFS uses lambda expressions to define transformations on data points as well as define Boolean conditions that act as filters. Lambda expressions wrap mathematical operations, Boolean operations, internal function calls or a combination of all three. All lambda expressions in DFS begin with the lambda: keyword. | where( lambda : \"topic\" == 'ttop/grap/prec' ) In the above example \"topic\" is used to access the value of a field called topic from the current data_point and compared against the string 'ttop/grap/prec' . Note here that literal string values are declared using single quotes, while double quotes are used only in lambda expressions to access the values of tags and fields. ! As field and tag values can be deeply nested maps and lists, it is possible to use a JSON-path like syntax to reference them: Valid examples: \"averages\" \"axis.z.cur\" \"value.sub[2].data\" \"averages.emitted[5]\" Built-in functions Type conversion With a few exceptions every type can be converted to every other type. Bool bool(a_value) -> true|false Integer int(value) -> integer Float float(value) -> float String string(val) -> string Time functions Every data_point in faxe contains a field called ts . Function Description to_iso8601(ts) -> string converts the timestamp to an ISO8601 string millisecond(ts) -> integer milliseconds within the second [0, 999] second(ts) -> integer second within the minute [0, 59] minute(ts) -> integer minute within the hour [0, 59] hour(ts) -> integer hour within the day [0, 23] day(ts) -> integer day within the month [1, 31] day_of_week(ts) -> integer the weekday with week [1, 7] 1 is monday week(ts) -> integer isoweek-number within year [1, 53] month(ts) -> integer month within the year [1, 12] Example: lambda : hour ( \"ts\" ) >= 8 AND hour ( \"ts\" ) < 19 The above expression evaluates to true if the hour of the day for the data point falls between 08:00 and 19:00. Math functions Function Description abs(x) -> number acos(x) -> float acosh(x) -> float asin(x) -> float asinh(x) -> float atan(x) -> float atan2(y, x) -> float atanh(x) -> float ceil(x) -> float cos(x) -> float cosh(x) -> float exp(x) -> float floor(x) -> float fmod(x, y) -> float log(x) -> float log10(x) -> float log2(x) -> float max(x, y) -> number min(x, y) -> number pow(x, y) -> float round(x) -> integer round a number to an integer round_float(x, precision) -> float round a float (x) with the given precision sin(x) -> float sinh(x) -> float sqrt(x) -> float tan(x) -> float tanh(x) -> float String functions Function Description str_at/2 str_capitalize/1 str_chunk/2 str_codepoints/1 str_contains/2 str_downcase/1 str_ends_with/2 str_ends_with_any/2 str_eqi/2 str_first/1 str_last/1 str_length/1 str_lstrip/1 str_lstrip/2 str_next_codepoint/1 str_normalize/2 str_pad_leading/2 str_pad_leading/3 str_pad_trailing/2 str_pad_trailing/3 str_replace/3 str_replace_leading/3 str_replace_prefix/3 str_replace_suffix/3 str_replace_trailing/3 str_reverse/1 str_rstrip/1 str_rstrip/2 str_slice/3 str_split/1 str_split/2 str_split/3 str_split_at/2 str_split_by_any/2 str_split_by_any/3 str_split_by_re/2 str_split_by_re/3 str_starts_with/2 str_starts_with_any/2 str_strip/1 str_strip/2 str_upcase/1 Conditional functions If Returns the result of its operands depending on the value of the first argument. The second and third arguments must return the same type. Example: | eval( lambda : if ( \"field.val1\" > threshold AND \"field.val1\" != 0 , 'true' , 'false' )) . as ( 'value' ) The value of the field value in the above example will be the string true or false , depending on the condition passed as the first argument. The if function\u2019s return type is the same type as its second and third arguments. if(condition, true expression, false expression)","title":"Lambda expressions"},{"location":"dfs_script_language/lambda_expressions.html#lambda-expressions","text":"","title":"Lambda expressions"},{"location":"dfs_script_language/lambda_expressions.html#overview","text":"DFS uses lambda expressions to define transformations on data points as well as define Boolean conditions that act as filters. Lambda expressions wrap mathematical operations, Boolean operations, internal function calls or a combination of all three. All lambda expressions in DFS begin with the lambda: keyword. | where( lambda : \"topic\" == 'ttop/grap/prec' ) In the above example \"topic\" is used to access the value of a field called topic from the current data_point and compared against the string 'ttop/grap/prec' . Note here that literal string values are declared using single quotes, while double quotes are used only in lambda expressions to access the values of tags and fields.","title":"Overview"},{"location":"dfs_script_language/lambda_expressions.html#_1","text":"As field and tag values can be deeply nested maps and lists, it is possible to use a JSON-path like syntax to reference them: Valid examples: \"averages\" \"axis.z.cur\" \"value.sub[2].data\" \"averages.emitted[5]\"","title":"!"},{"location":"dfs_script_language/lambda_expressions.html#built-in-functions","text":"","title":"Built-in functions"},{"location":"dfs_script_language/lambda_expressions.html#type-conversion","text":"With a few exceptions every type can be converted to every other type. Bool bool(a_value) -> true|false Integer int(value) -> integer Float float(value) -> float String string(val) -> string","title":"Type conversion"},{"location":"dfs_script_language/lambda_expressions.html#time-functions","text":"Every data_point in faxe contains a field called ts . Function Description to_iso8601(ts) -> string converts the timestamp to an ISO8601 string millisecond(ts) -> integer milliseconds within the second [0, 999] second(ts) -> integer second within the minute [0, 59] minute(ts) -> integer minute within the hour [0, 59] hour(ts) -> integer hour within the day [0, 23] day(ts) -> integer day within the month [1, 31] day_of_week(ts) -> integer the weekday with week [1, 7] 1 is monday week(ts) -> integer isoweek-number within year [1, 53] month(ts) -> integer month within the year [1, 12] Example: lambda : hour ( \"ts\" ) >= 8 AND hour ( \"ts\" ) < 19 The above expression evaluates to true if the hour of the day for the data point falls between 08:00 and 19:00.","title":"Time functions"},{"location":"dfs_script_language/lambda_expressions.html#math-functions","text":"Function Description abs(x) -> number acos(x) -> float acosh(x) -> float asin(x) -> float asinh(x) -> float atan(x) -> float atan2(y, x) -> float atanh(x) -> float ceil(x) -> float cos(x) -> float cosh(x) -> float exp(x) -> float floor(x) -> float fmod(x, y) -> float log(x) -> float log10(x) -> float log2(x) -> float max(x, y) -> number min(x, y) -> number pow(x, y) -> float round(x) -> integer round a number to an integer round_float(x, precision) -> float round a float (x) with the given precision sin(x) -> float sinh(x) -> float sqrt(x) -> float tan(x) -> float tanh(x) -> float","title":"Math functions"},{"location":"dfs_script_language/lambda_expressions.html#string-functions","text":"Function Description str_at/2 str_capitalize/1 str_chunk/2 str_codepoints/1 str_contains/2 str_downcase/1 str_ends_with/2 str_ends_with_any/2 str_eqi/2 str_first/1 str_last/1 str_length/1 str_lstrip/1 str_lstrip/2 str_next_codepoint/1 str_normalize/2 str_pad_leading/2 str_pad_leading/3 str_pad_trailing/2 str_pad_trailing/3 str_replace/3 str_replace_leading/3 str_replace_prefix/3 str_replace_suffix/3 str_replace_trailing/3 str_reverse/1 str_rstrip/1 str_rstrip/2 str_slice/3 str_split/1 str_split/2 str_split/3 str_split_at/2 str_split_by_any/2 str_split_by_any/3 str_split_by_re/2 str_split_by_re/3 str_starts_with/2 str_starts_with_any/2 str_strip/1 str_strip/2 str_upcase/1","title":"String functions"},{"location":"dfs_script_language/lambda_expressions.html#conditional-functions","text":"If Returns the result of its operands depending on the value of the first argument. The second and third arguments must return the same type. Example: | eval( lambda : if ( \"field.val1\" > threshold AND \"field.val1\" != 0 , 'true' , 'false' )) . as ( 'value' ) The value of the field value in the above example will be the string true or false , depending on the condition passed as the first argument. The if function\u2019s return type is the same type as its second and third arguments. if(condition, true expression, false expression)","title":"Conditional functions"},{"location":"nodes/index.html","text":"Faxe nodes Parameters Faxe nodes can have 2 types of parameters : Node parameters provided to the node declaration function % the level parameter is given to the node declaration function | debug( 'notice' ) Option parameters provided to an option call % the level parameter is given as an extra option function | debug() . level ( 'notice' ) Some parameters are required and others are optional. Every parameter with no default value is mandatory ! The following is a list of all possible parameter types faxe supports based on the basic data-types: Name Description Example is_set Special parameter type that evaluates to true if called (even with no value) .use_ssl() number Integer or float value 324 or 4.3424325 integer Integer value float Floating point value double Floating point value string String value .topic('home/alex/garage') binary atom used internally only list any kind of list lambda a lambda expression bool number_list a list of numbers .values(3, 44, 34.5) integer_list a list of integers .ints(2, 3, 4, 5) float_list a list of floats .floats(43.4, 12.2, 545.009832) string_list a list of strings .strings('alex1', 'alex2', 'flo', 'markus') binary_list atom_list internally only lambda_list a list of lambda expressions .functions(lambda: \"val\" * 2, lambda: \"val\" * 3, lambda: \"val\" / 4) What is important to note: If a node requires a _list type for any parameter, we just provide 1 or more of the same data-type separated be commas. For example the eval node requires the lambdas parameter to be of type lambda_list , the following calls would be valid: |eval(lambda: str_concat(\"strval\", '_postfix') |eval(lambda: str_starts_with(\"strval\", 'pre'), lambda: 3 * (\"val1\" + \"val2\")) |eval( lambda: sqrt(\"base\") + const, lambda: if(hour(\"ts\") > 18 AND day_of_week(\"ts\") < 6, 'late_for_work', 'ok') lambda: abs(\"ts\" - \"ts_previous\") )","title":"Faxe nodes"},{"location":"nodes/index.html#faxe-nodes","text":"","title":"Faxe nodes"},{"location":"nodes/index.html#parameters","text":"Faxe nodes can have 2 types of parameters : Node parameters provided to the node declaration function % the level parameter is given to the node declaration function | debug( 'notice' ) Option parameters provided to an option call % the level parameter is given as an extra option function | debug() . level ( 'notice' ) Some parameters are required and others are optional. Every parameter with no default value is mandatory ! The following is a list of all possible parameter types faxe supports based on the basic data-types: Name Description Example is_set Special parameter type that evaluates to true if called (even with no value) .use_ssl() number Integer or float value 324 or 4.3424325 integer Integer value float Floating point value double Floating point value string String value .topic('home/alex/garage') binary atom used internally only list any kind of list lambda a lambda expression bool number_list a list of numbers .values(3, 44, 34.5) integer_list a list of integers .ints(2, 3, 4, 5) float_list a list of floats .floats(43.4, 12.2, 545.009832) string_list a list of strings .strings('alex1', 'alex2', 'flo', 'markus') binary_list atom_list internally only lambda_list a list of lambda expressions .functions(lambda: \"val\" * 2, lambda: \"val\" * 3, lambda: \"val\" / 4) What is important to note: If a node requires a _list type for any parameter, we just provide 1 or more of the same data-type separated be commas. For example the eval node requires the lambdas parameter to be of type lambda_list , the following calls would be valid: |eval(lambda: str_concat(\"strval\", '_postfix') |eval(lambda: str_starts_with(\"strval\", 'pre'), lambda: 3 * (\"val1\" + \"val2\")) |eval( lambda: sqrt(\"base\") + const, lambda: if(hour(\"ts\") > 18 AND day_of_week(\"ts\") < 6, 'late_for_work', 'ok') lambda: abs(\"ts\" - \"ts_previous\") )","title":"Parameters"},{"location":"nodes/amqp_consume.html","text":"The amqp_consume node Consume data from an amqp-broker like rabbitmq. When prefetch is given and is > 1, then this node will emit a data_batch instead of a data_point. Example | amqp_consume() . host ( 'deves-amqp-cluster1.internal' ) . routing_key ( 'my.routing.key' ) . exchange ( 'x_xchange' ) . queue ( 'faxe_test' ) . dt_field ( 'UTC-Time' ) . dt_format ( 'float_micro' ) Parameters Parameter Description Default host( string ) Ip address or hostname of the broker port( integer ) The broker's port 5672 vhost( string ) vhost to connect to on the broker '/' routing_key( string ) routing key to use for queue binding queue( string ) name of the queue to bind to the exchange exchange( string ) name of the exchange to bind to the source prefetch( integer ) prefetch count to use 1 dt_field( string ) name of the timestamp field that is expected 'ts' dt_format( string ) timestamp or datetime format that is expected (see table below) 'millisecond' ssl( is_set ) whether to use ssl false (not set) Available datetime formats dt_format description example 'millisecond' timestamp UTC in milliseconds 1565343079000 'second' timestamp UTC in seconds 1565343079 'float_micro' timestamp UTC float with microsecond precision 1565343079.173588 'float_millisecond' timestamp UTC float with millisecond precision 1565343079.173 'ISO8601' ISO8601 Datetime format string '2011-10-05T14:48:00.000Z' 'RFC3339' RFC3339 Datetime format string '2018-02-01 15:18:02.088Z' 'convtrack_datetime' special datetime format used in the conveyor tracking data stream '19.08.01 17:33:44,867 '","title":"Amqp consume"},{"location":"nodes/amqp_consume.html#the-amqp_consume-node","text":"Consume data from an amqp-broker like rabbitmq. When prefetch is given and is > 1, then this node will emit a data_batch instead of a data_point.","title":"The amqp_consume node"},{"location":"nodes/amqp_consume.html#example","text":"| amqp_consume() . host ( 'deves-amqp-cluster1.internal' ) . routing_key ( 'my.routing.key' ) . exchange ( 'x_xchange' ) . queue ( 'faxe_test' ) . dt_field ( 'UTC-Time' ) . dt_format ( 'float_micro' )","title":"Example"},{"location":"nodes/amqp_consume.html#parameters","text":"Parameter Description Default host( string ) Ip address or hostname of the broker port( integer ) The broker's port 5672 vhost( string ) vhost to connect to on the broker '/' routing_key( string ) routing key to use for queue binding queue( string ) name of the queue to bind to the exchange exchange( string ) name of the exchange to bind to the source prefetch( integer ) prefetch count to use 1 dt_field( string ) name of the timestamp field that is expected 'ts' dt_format( string ) timestamp or datetime format that is expected (see table below) 'millisecond' ssl( is_set ) whether to use ssl false (not set)","title":"Parameters"},{"location":"nodes/amqp_consume.html#available-datetime-formats","text":"dt_format description example 'millisecond' timestamp UTC in milliseconds 1565343079000 'second' timestamp UTC in seconds 1565343079 'float_micro' timestamp UTC float with microsecond precision 1565343079.173588 'float_millisecond' timestamp UTC float with millisecond precision 1565343079.173 'ISO8601' ISO8601 Datetime format string '2011-10-05T14:48:00.000Z' 'RFC3339' RFC3339 Datetime format string '2018-02-01 15:18:02.088Z' 'convtrack_datetime' special datetime format used in the conveyor tracking data stream '19.08.01 17:33:44,867 '","title":"Available datetime formats"},{"location":"nodes/amqp_publish.html","text":"The amqp_publish node Publish data to an amqp-broker exchange like rabbitmq. Incoming data is converted to JSON before sending. Example | amqp_publish() . host ( '127.0.0.1' ) . routing_key ( 'my.routing.key' ) . exchange ( 'x_xchange' ) Parameters Parameter Description Default host( string ) Ip address or hostname of the broker port( integer ) The broker's port 5672 vhost( string ) vhost to connect to on the broker '/' routing_key( string ) routing key for the published messages exchange( string ) name of the exchange to publish to ssl( is_set ) whether to use ssl false (not set)","title":"Amqp publish"},{"location":"nodes/amqp_publish.html#the-amqp_publish-node","text":"Publish data to an amqp-broker exchange like rabbitmq. Incoming data is converted to JSON before sending.","title":"The amqp_publish node"},{"location":"nodes/amqp_publish.html#example","text":"| amqp_publish() . host ( '127.0.0.1' ) . routing_key ( 'my.routing.key' ) . exchange ( 'x_xchange' )","title":"Example"},{"location":"nodes/amqp_publish.html#parameters","text":"Parameter Description Default host( string ) Ip address or hostname of the broker port( integer ) The broker's port 5672 vhost( string ) vhost to connect to on the broker '/' routing_key( string ) routing key for the published messages exchange( string ) name of the exchange to publish to ssl( is_set ) whether to use ssl false (not set)","title":"Parameters"},{"location":"nodes/batch.html","text":"The batch node Used to batch a number of points. As soon as the node has collected size number of points it will emit them in a data_batch. A timeout can be set, after which all points currently in the buffer will be emitted, regardless of the number of collected points. The timeout is started on the first datapoint coming in to an empty buffer. Example | batch( 12 ) | batch( 5 ) . timeout ( 3s ) The second example will output a batch with 5 points. If the points come in within 3 seconds the node will emit them in a databatch and reset the timeout. If after 3 seconds there are less than 5 points in the buffer, the node will emit them, regardless of the number. Parameters Parameter Description Default [node] size( integer ) Number of points to batch timeout( duration ) optional","title":"Batch"},{"location":"nodes/batch.html#the-batch-node","text":"Used to batch a number of points. As soon as the node has collected size number of points it will emit them in a data_batch. A timeout can be set, after which all points currently in the buffer will be emitted, regardless of the number of collected points. The timeout is started on the first datapoint coming in to an empty buffer.","title":"The batch node"},{"location":"nodes/batch.html#example","text":"| batch( 12 ) | batch( 5 ) . timeout ( 3s ) The second example will output a batch with 5 points. If the points come in within 3 seconds the node will emit them in a databatch and reset the timeout. If after 3 seconds there are less than 5 points in the buffer, the node will emit them, regardless of the number.","title":"Example"},{"location":"nodes/batch.html#parameters","text":"Parameter Description Default [node] size( integer ) Number of points to batch timeout( duration ) optional","title":"Parameters"},{"location":"nodes/case.html","text":"The case node Evaluates a series of lambda expressions in a top down manner. The node will output / add the corresponding value of the first lambda expression that evaluates as true. If none of the lambda expressions evaluate as true, a default value will be used The case node works in a similar way CASE expressions in SQL work. Example | case( lambda : \"data.condition.name\" == 'OK' , lambda : \"data.condition.name\" == 'Warning' , lambda : \"data.condition.name\" == 'Error' ) . values ( <<<{\"cond\": \"Everything OK!\"}>>>, <<<{\"cond\": \"Oh, oh, a Warning!\"}>>>, <<<{\"cond\": \"Damn, Error!\"}>>> ) . json () . as ( 'data' ) .default( <<< { \"cond\" : \"Nothing matched!!!\" } >>> ) Parameters Parameter Description Default [node] lambdas( lambda_list ) list of lambda expressions values( string_list\\|text_list ) corresponding values json( is_set ) if set, will treat the values and default parameters as json strings false, not set as ( string ) field-path for the output value default( any ) default value to use, if no case clause matches","title":"Case"},{"location":"nodes/case.html#the-case-node","text":"Evaluates a series of lambda expressions in a top down manner. The node will output / add the corresponding value of the first lambda expression that evaluates as true. If none of the lambda expressions evaluate as true, a default value will be used The case node works in a similar way CASE expressions in SQL work.","title":"The case node"},{"location":"nodes/case.html#example","text":"| case( lambda : \"data.condition.name\" == 'OK' , lambda : \"data.condition.name\" == 'Warning' , lambda : \"data.condition.name\" == 'Error' ) . values ( <<<{\"cond\": \"Everything OK!\"}>>>, <<<{\"cond\": \"Oh, oh, a Warning!\"}>>>, <<<{\"cond\": \"Damn, Error!\"}>>> ) . json () . as ( 'data' ) .default( <<< { \"cond\" : \"Nothing matched!!!\" } >>> )","title":"Example"},{"location":"nodes/case.html#parameters","text":"Parameter Description Default [node] lambdas( lambda_list ) list of lambda expressions values( string_list\\|text_list ) corresponding values json( is_set ) if set, will treat the values and default parameters as json strings false, not set as ( string ) field-path for the output value default( any ) default value to use, if no case clause matches","title":"Parameters"},{"location":"nodes/change_detect.html","text":"The change_detect node Emits new point-values only if different from the previous point. Multiple fields can be monitored for change by this node If no fields are given, a new datapoint is used to compare If reset_timeout is given, all previous values are reset, if there are no points coming in for this amount of time For value comparison erlang's strict equals (=:=) is used, so 1.0 is not equal to 1 Example %% detects any changes | change_detect() %% detect changes in one field, with timeout | change_detect() . fields ( 'val' ) . reset_timeout ( 3s ) % in example json notation: % {\"data\": {\"x\": {\"temp\": 32.4564}, \"y\" : {\"temp\" : 31.15155}} } | change_detect() . fields ( 'data.x.temp' , 'data.y.temp' ) Parameters Parameter Description Default fields( string_list ) List of fields to monitor optional reset_timeout( duration ) Previous values TTL 3h","title":"Change detect"},{"location":"nodes/change_detect.html#the-change_detect-node","text":"Emits new point-values only if different from the previous point. Multiple fields can be monitored for change by this node If no fields are given, a new datapoint is used to compare If reset_timeout is given, all previous values are reset, if there are no points coming in for this amount of time For value comparison erlang's strict equals (=:=) is used, so 1.0 is not equal to 1","title":"The change_detect node"},{"location":"nodes/change_detect.html#example","text":"%% detects any changes | change_detect() %% detect changes in one field, with timeout | change_detect() . fields ( 'val' ) . reset_timeout ( 3s ) % in example json notation: % {\"data\": {\"x\": {\"temp\": 32.4564}, \"y\" : {\"temp\" : 31.15155}} } | change_detect() . fields ( 'data.x.temp' , 'data.y.temp' )","title":"Example"},{"location":"nodes/change_detect.html#parameters","text":"Parameter Description Default fields( string_list ) List of fields to monitor optional reset_timeout( duration ) Previous values TTL 3h","title":"Parameters"},{"location":"nodes/combine.html","text":"The combine node Combine the values of 2 nodes, use to enrich data from one node. Port 1 is the trigger port. Every time a value is received on the trigger port, the node will emit a value, combined with whatever current value on port 2. The node will never emit on port 2 values. No output is given, as long as there has not arrived a value on port 2 to combine with. The fields parameter defines the fields to inject into the combination for the stream on port 2. To rename these fields, parameter prefix or aliases can be used. With prefix_delimiter a delimiter can be given, defaults to: '_' Example def in1 = | value_emitter() . every ( 500ms ) . type ( point ) . fields ( 'val' ) def in2 = | value_emitter() . every ( 4s ) . type ( point ) . fields ( 'val2' , 'val3' ) in1 | combine( in2 ) . fields ( 'val2' , 'val3' ) . prefix ( 'comb' ) . prefix_delimiter ( '_' ) In this example values from the stream called in1 will be enriched with values from in2 . Outputfields will be called: val , comb_val2 and comb_val3 . The flow will emit every 500 milliseconds after 4 seconds have past initially. Parameters Parameter Description Default fields( string_list ) List of fields to include [] tags( string_list ) List of tags to include [] aliases( string_list ) List of field aliases to use instead of the original field names [] prefix( string ) Prefix for the injected fields from stream 2 undefined prefix_delimiter( string ) Used to separate prefix and the original field name from stream 2 '_' Either prefix or aliases must be given these are mutually exclusive parameters. If both are given, then prefix will win.","title":"Combine"},{"location":"nodes/combine.html#the-combine-node","text":"Combine the values of 2 nodes, use to enrich data from one node. Port 1 is the trigger port. Every time a value is received on the trigger port, the node will emit a value, combined with whatever current value on port 2. The node will never emit on port 2 values. No output is given, as long as there has not arrived a value on port 2 to combine with. The fields parameter defines the fields to inject into the combination for the stream on port 2. To rename these fields, parameter prefix or aliases can be used. With prefix_delimiter a delimiter can be given, defaults to: '_'","title":"The combine node"},{"location":"nodes/combine.html#example","text":"def in1 = | value_emitter() . every ( 500ms ) . type ( point ) . fields ( 'val' ) def in2 = | value_emitter() . every ( 4s ) . type ( point ) . fields ( 'val2' , 'val3' ) in1 | combine( in2 ) . fields ( 'val2' , 'val3' ) . prefix ( 'comb' ) . prefix_delimiter ( '_' ) In this example values from the stream called in1 will be enriched with values from in2 . Outputfields will be called: val , comb_val2 and comb_val3 . The flow will emit every 500 milliseconds after 4 seconds have past initially.","title":"Example"},{"location":"nodes/combine.html#parameters","text":"Parameter Description Default fields( string_list ) List of fields to include [] tags( string_list ) List of tags to include [] aliases( string_list ) List of field aliases to use instead of the original field names [] prefix( string ) Prefix for the injected fields from stream 2 undefined prefix_delimiter( string ) Used to separate prefix and the original field name from stream 2 '_' Either prefix or aliases must be given these are mutually exclusive parameters. If both are given, then prefix will win.","title":"Parameters"},{"location":"nodes/crate_query.html","text":"The crate_query node Query the CRATE database for time series data . This node is experimental . The select statement will be executed periodically according to the every parameter. Each time the database is queried, the timestamps will be set according to period . Example def host = '10.14.204.8' def port = 5433 def query = <<< SELECT avg(data_obj['x']['cur']) AS x_cur, avg(data_obj['y']['cur']) AS y_cur, avg(data_obj['z']['cur']) AS z_cur, avg(data_obj['yaw']['cur']) AS yaw_cur, avg(data_obj['pitch']['cur']) AS pitch_cur FROM robotplc_parted; >>> def s = | crate_query() . host ( host ) . port ( port ) . user ( 'crate' ) . database ( 'doc' ) . query ( query ) . group_by_time ( 3m ) . every ( 15s ) . period ( 30m ) . align () The above example will execute the query every 15 seconds. It get data which is in the timerange now -30 minutes and now . Parameters Parameter Description Default host( string ) CrateDB host from config file port( integer ) CrateDB port from config file user( string ) username from config file pass( string ) password from config file database( string ) Database name from config file query( string text ) 'SELECT-FROM' query clause time_field( string ) name of the timefield to use 'ts' every( duration ) time between query execution 5s period( duration ) time span of data to query 1h align( is_set ) whether to align period to full every durations false (not set) group_by_time( duration ) group the aggregations into time buckets 2m group_by( string_list ) additional group by [] limit( string ) LIMIT statement '30'","title":"Crate query"},{"location":"nodes/crate_query.html#the-crate_query-node","text":"Query the CRATE database for time series data . This node is experimental . The select statement will be executed periodically according to the every parameter. Each time the database is queried, the timestamps will be set according to period .","title":"The crate_query node"},{"location":"nodes/crate_query.html#example","text":"def host = '10.14.204.8' def port = 5433 def query = <<< SELECT avg(data_obj['x']['cur']) AS x_cur, avg(data_obj['y']['cur']) AS y_cur, avg(data_obj['z']['cur']) AS z_cur, avg(data_obj['yaw']['cur']) AS yaw_cur, avg(data_obj['pitch']['cur']) AS pitch_cur FROM robotplc_parted; >>> def s = | crate_query() . host ( host ) . port ( port ) . user ( 'crate' ) . database ( 'doc' ) . query ( query ) . group_by_time ( 3m ) . every ( 15s ) . period ( 30m ) . align () The above example will execute the query every 15 seconds. It get data which is in the timerange now -30 minutes and now .","title":"Example"},{"location":"nodes/crate_query.html#parameters","text":"Parameter Description Default host( string ) CrateDB host from config file port( integer ) CrateDB port from config file user( string ) username from config file pass( string ) password from config file database( string ) Database name from config file query( string text ) 'SELECT-FROM' query clause time_field( string ) name of the timefield to use 'ts' every( duration ) time between query execution 5s period( duration ) time span of data to query 1h align( is_set ) whether to align period to full every durations false (not set) group_by_time( duration ) group the aggregations into time buckets 2m group_by( string_list ) additional group by [] limit( string ) LIMIT statement '30'","title":"Parameters"},{"location":"nodes/deadman.html","text":"The deadman node Emits a point, if there is no point coming in for the given amount of time. For output there are two options: If repeat_last param if set, the node will output the last message it saw incoming as the dead-message, if there is no last message yet, an empty message will be emitted Multiple field and field_value can be provided to be included in the output If no fields (and field_values) parameter and is given, an empty datapoint will be emitted The repeat_last parameter will always override the fields and field_values parameter The node will forward every message it gets by default, this can be changed by using the no_forward flag Example | deadman( 15s ) Parameters Parameter Description Default [node] lambdas( lambda_list ) list of lambda expressions values( string_list\\|text_list ) corresponding values json( is_set ) if set, will treat the values and default parameters as json strings false, not set as ( string ) field-path for the output value default( any ) default value to use, if no case clause matches","title":"Deadman"},{"location":"nodes/deadman.html#the-deadman-node","text":"Emits a point, if there is no point coming in for the given amount of time. For output there are two options: If repeat_last param if set, the node will output the last message it saw incoming as the dead-message, if there is no last message yet, an empty message will be emitted Multiple field and field_value can be provided to be included in the output If no fields (and field_values) parameter and is given, an empty datapoint will be emitted The repeat_last parameter will always override the fields and field_values parameter The node will forward every message it gets by default, this can be changed by using the no_forward flag","title":"The deadman node"},{"location":"nodes/deadman.html#example","text":"| deadman( 15s )","title":"Example"},{"location":"nodes/deadman.html#parameters","text":"Parameter Description Default [node] lambdas( lambda_list ) list of lambda expressions values( string_list\\|text_list ) corresponding values json( is_set ) if set, will treat the values and default parameters as json strings false, not set as ( string ) field-path for the output value default( any ) default value to use, if no case clause matches","title":"Parameters"},{"location":"nodes/debug.html","text":"The debug node The debug node logs all incoming data with erlang's lager framework and emits it, without touching it. Where the logs will be written, depends on the lager config. See rest api for how to read the produced logs. Example | debug() | debug( 'error' ) Parameters Parameter Description Default [node] level ( string ) log level (see below) 'notice' The level parameter must have one of the following values: log_level debug info notice warning error critical alert","title":"Debug"},{"location":"nodes/debug.html#the-debug-node","text":"The debug node logs all incoming data with erlang's lager framework and emits it, without touching it. Where the logs will be written, depends on the lager config. See rest api for how to read the produced logs.","title":"The debug node"},{"location":"nodes/debug.html#example","text":"| debug() | debug( 'error' )","title":"Example"},{"location":"nodes/debug.html#parameters","text":"Parameter Description Default [node] level ( string ) log level (see below) 'notice' The level parameter must have one of the following values: log_level debug info notice warning error critical alert","title":"Parameters"},{"location":"nodes/default.html","text":"The default node Add fields and/or tags to a data_point or batch if they do not already exist. Does not overwrite or update any fields or tags. Note: This nodes checks for existence of fields before writing them. Consider using the set node , if you just want some fields set. It is more performant especially with high frequency data streams. Example | default() . fields ( 'id' , 'vs' , 'df' ) . field_values ( 'some_id' , 1 , '05.043' ) The above example will set the field id to the value 'some_id' , if a field with the name id does not already exist. Accordingly vs will be set to 1, df will be set to '05.043'. Parameters Parameter Description Default fields( string_list ) list of fieldnames [] field_values( list ) list of values for the given fields (must have the same length as fieldnames) [] tags( string_list ) list of tagnames [] tag_values( list ) list of values for the given tags (must have the same length as tagnames) []","title":"Default"},{"location":"nodes/default.html#the-default-node","text":"Add fields and/or tags to a data_point or batch if they do not already exist. Does not overwrite or update any fields or tags. Note: This nodes checks for existence of fields before writing them. Consider using the set node , if you just want some fields set. It is more performant especially with high frequency data streams.","title":"The default node"},{"location":"nodes/default.html#example","text":"| default() . fields ( 'id' , 'vs' , 'df' ) . field_values ( 'some_id' , 1 , '05.043' ) The above example will set the field id to the value 'some_id' , if a field with the name id does not already exist. Accordingly vs will be set to 1, df will be set to '05.043'.","title":"Example"},{"location":"nodes/default.html#parameters","text":"Parameter Description Default fields( string_list ) list of fieldnames [] field_values( list ) list of values for the given fields (must have the same length as fieldnames) [] tags( string_list ) list of tagnames [] tag_values( list ) list of values for the given tags (must have the same length as tagnames) []","title":"Parameters"},{"location":"nodes/delete.html","text":"The delete node Delete fields and/or tags from a data_point or from all data_points in a data_batch. Example | delete() . fields ( 'temp' , 'data.meta[3]' ) The above example will delete the field named temp and the third array entry of the field data.meta . Parameters Parameter Description Default fields( string_list ) list of fieldnames to delete [] tags( string_list ) list of tagnames to delete []","title":"Delete"},{"location":"nodes/delete.html#the-delete-node","text":"Delete fields and/or tags from a data_point or from all data_points in a data_batch.","title":"The delete node"},{"location":"nodes/delete.html#example","text":"| delete() . fields ( 'temp' , 'data.meta[3]' ) The above example will delete the field named temp and the third array entry of the field data.meta .","title":"Example"},{"location":"nodes/delete.html#parameters","text":"Parameter Description Default fields( string_list ) list of fieldnames to delete [] tags( string_list ) list of tagnames to delete []","title":"Parameters"},{"location":"nodes/email.html","text":"The email node Send an email to one or more recipients Example | email() . to ( <<< name @ email. com >>> , <<< another @ email. com >>> ) . subject ( 'Alert #ex3 EnergyData' ) . body ( <<< No data since {{ \"datetime\" }} on topic 'home/garage/energy' , last value was {{ \"val\" }}. >>> ) Sends an email with the subject 'Alert #ex3 EnergyData' to 2 recipients. The body will be rendered into an html template (see parameters). Body is a text_template parameter with two template-values: datetime and val , these two fields must be present in the data_point last received in the email node. If a field used in a text_template is not found in the current data_point, the string 'undefined' will be used. Parameters Parameter Description Default to( string_list ) the recipient email addresses subject( string ) body( text_template ) body_field( string ) field_path used to get the body string template ( string ) html email template to use from config file from_address ( string ) from config file smtp_relay( string ) from config file smtp_user ( string ) from config file smtp_pass ( string ) from config file body or body_field must be provided.","title":"Email"},{"location":"nodes/email.html#the-email-node","text":"Send an email to one or more recipients","title":"The email node"},{"location":"nodes/email.html#example","text":"| email() . to ( <<< name @ email. com >>> , <<< another @ email. com >>> ) . subject ( 'Alert #ex3 EnergyData' ) . body ( <<< No data since {{ \"datetime\" }} on topic 'home/garage/energy' , last value was {{ \"val\" }}. >>> ) Sends an email with the subject 'Alert #ex3 EnergyData' to 2 recipients. The body will be rendered into an html template (see parameters). Body is a text_template parameter with two template-values: datetime and val , these two fields must be present in the data_point last received in the email node. If a field used in a text_template is not found in the current data_point, the string 'undefined' will be used.","title":"Example"},{"location":"nodes/email.html#parameters","text":"Parameter Description Default to( string_list ) the recipient email addresses subject( string ) body( text_template ) body_field( string ) field_path used to get the body string template ( string ) html email template to use from config file from_address ( string ) from config file smtp_relay( string ) from config file smtp_user ( string ) from config file smtp_pass ( string ) from config file body or body_field must be provided.","title":"Parameters"},{"location":"nodes/eval.html","text":"The eval node Evaluate one or more lambda expressions. For an explanation of lambdas, see lambda . The list of lambda expressions given, will be evaluated in a serial fashion. This means that a lambda can use the result of a previous expression. Examples | eval() . lambdas ( lambda : \"val\" * 2 , lambda : \"double\" / 2 ) . as ( 'double' , 'val' ) This example demonstrates the 'serial' behaviour of the eval node. The second expression uses the field double , which the first expression just created. |eval() .lambdas( lambda: int(str_concat(string(int(\"val\")),string(int(\"val\")))) ) .as('concat_string.int') The above example uses several built in casting and string functions to demonstrate complex expressions. For more lambda examples see lambda Parameters Parameter Description Default lambdas( lambda_list ) list of lambda expressions as( string_list ) list of output fieldnames (must have the same length as lambdas ) tags ( string_list ) list of output tagnames []","title":"Eval"},{"location":"nodes/eval.html#the-eval-node","text":"Evaluate one or more lambda expressions. For an explanation of lambdas, see lambda . The list of lambda expressions given, will be evaluated in a serial fashion. This means that a lambda can use the result of a previous expression.","title":"The eval node"},{"location":"nodes/eval.html#examples","text":"| eval() . lambdas ( lambda : \"val\" * 2 , lambda : \"double\" / 2 ) . as ( 'double' , 'val' ) This example demonstrates the 'serial' behaviour of the eval node. The second expression uses the field double , which the first expression just created. |eval() .lambdas( lambda: int(str_concat(string(int(\"val\")),string(int(\"val\")))) ) .as('concat_string.int') The above example uses several built in casting and string functions to demonstrate complex expressions. For more lambda examples see lambda","title":"Examples"},{"location":"nodes/eval.html#parameters","text":"Parameter Description Default lambdas( lambda_list ) list of lambda expressions as( string_list ) list of output fieldnames (must have the same length as lambdas ) tags ( string_list ) list of output tagnames []","title":"Parameters"},{"location":"nodes/http_post.html","text":"The http_post node Sends incoming data to a specified HTTP endpoint via the POST method as a JSON message. If any errors occur during the request, the node will attempt to retry sending. Example | http_post() . host ( 'remote.com' ) . port ( 8088 ) . path ( '/receive/json' ) Sends all incoming data to http://remote.com:8088/receive/json in JSON format. Parameters Parameter Description Default host( string ) hostname or ip address of endpoint port( integer ) port number path( string ) URI path of the http endpoint ''","title":"Http post"},{"location":"nodes/http_post.html#the-http_post-node","text":"Sends incoming data to a specified HTTP endpoint via the POST method as a JSON message. If any errors occur during the request, the node will attempt to retry sending.","title":"The http_post node"},{"location":"nodes/http_post.html#example","text":"| http_post() . host ( 'remote.com' ) . port ( 8088 ) . path ( '/receive/json' ) Sends all incoming data to http://remote.com:8088/receive/json in JSON format.","title":"Example"},{"location":"nodes/http_post.html#parameters","text":"Parameter Description Default host( string ) hostname or ip address of endpoint port( integer ) port number path( string ) URI path of the http endpoint ''","title":"Parameters"},{"location":"nodes/http_post_crate.html","text":"The http_post_crate node Sends data to a CRATE DB HTTP endpoint using Crate's HTTP Api. If any errors occur during the request, the node will attempt to retry sending. Example def db_table = 'grip_log_fulltext3' def db_fields = [ 'id' , 'df' , 'vs' , 'topic' ] def faxe_fields = [ 'id' , 'df' , 'vs' , 'topic' ] | http_post_crate() . host ( <<< http : //deves-crate.internal >>>) . port ( 4201 ) . table ( db_table ) . db_fields ( db_fields ) . faxe_fields ( faxe_fields ) . remaining_fields_as ( 'data_obj' ) Inserts the faxe-fields id , df , vs , topic into the db-fields with the same names and all remaining fields into the db-field named data_obj (which is of type 'OBJECT') in the table grip_log_fulltext3 . Parameters Parameter Description Default host( string ) hostname or ip address of endpoint port( integer ) port number table( string ) database tablename 'doc' db_fields( string_list ) db fieldnames (mapping for faxe fieldname to table field names) faxe_fields( string_list ) faxe fieldnames (mapping for faxe fieldname to table field names) remaining_fields_as( string ) if given inserts all fields not in faxe_fields into the given field, which must be of type 'object' undefined","title":"Http post crate"},{"location":"nodes/http_post_crate.html#the-http_post_crate-node","text":"Sends data to a CRATE DB HTTP endpoint using Crate's HTTP Api. If any errors occur during the request, the node will attempt to retry sending.","title":"The http_post_crate node"},{"location":"nodes/http_post_crate.html#example","text":"def db_table = 'grip_log_fulltext3' def db_fields = [ 'id' , 'df' , 'vs' , 'topic' ] def faxe_fields = [ 'id' , 'df' , 'vs' , 'topic' ] | http_post_crate() . host ( <<< http : //deves-crate.internal >>>) . port ( 4201 ) . table ( db_table ) . db_fields ( db_fields ) . faxe_fields ( faxe_fields ) . remaining_fields_as ( 'data_obj' ) Inserts the faxe-fields id , df , vs , topic into the db-fields with the same names and all remaining fields into the db-field named data_obj (which is of type 'OBJECT') in the table grip_log_fulltext3 .","title":"Example"},{"location":"nodes/http_post_crate.html#parameters","text":"Parameter Description Default host( string ) hostname or ip address of endpoint port( integer ) port number table( string ) database tablename 'doc' db_fields( string_list ) db fieldnames (mapping for faxe fieldname to table field names) faxe_fields( string_list ) faxe fieldnames (mapping for faxe fieldname to table field names) remaining_fields_as( string ) if given inserts all fields not in faxe_fields into the given field, which must be of type 'object' undefined","title":"Parameters"},{"location":"nodes/join.html","text":"The join node Join data from two or more nodes, given a list of prefixes, for each row. If the field_merge parameter is given, the node will merge the field given from every in-node, instead of joining. When considering the fill option, the following rules apply: 'none' - (default) skip rows where a point is missing, inner join. 'null' - fill missing points with null, full outer join. Any value - fill fields with given value, full outer join. Note, that this node will produce a completely new stream. Example def v1 = | value_emitter() . every ( 3s ) . type ( point ) . align () def v2 = | value_emitter() . every ( 5s ) . type ( point ) . align () v1 | join( v2 ) . prefix ( 'v1.joined' , 'v2.joined' ) . tolerance ( 3s ) . missing_timeout ( 3s ) . fill ( none ) Joins the fields of v1 and v2 and produces a stream, that has the fields v1.joined.val and v2.joined.val Node Parameters Parameter Description Default nodes( node_list ) list of node (chains) to merge [] Parameters Parameter Description Default prefix( string_list ) list of prefixes (used in join mode) ['', ''] (no prefixes) field_merge( string ) when given, the join node will do a field merge operation undefined missing_timeout( duration ) values that do not arrive within this timeout will be treated as missing 20s tolerance( duration ) db fieldnames (mapping for faxe fieldname to table field names) fill( 'none' 'null' any ) fill missing values / join behaviour 'none' Merge example Let's look at an example where the streams coming out of two nodes are not joined with prefixes, but a merge operation is performed. def v1 = | json_emitter() . every ( 3s ) . json ( <<< { \"condition\" : { \"id\" : 0 , \"name\" : \"OK\" , \"sub_cond\" : [{ \"value\" : 33 }]}, \"condition_reason\" : \"\" , \"predicted_maintenance_time\" : 1584246411783 , \"vac_on_without_contact\" : [ 1.2 , 2.5 , 4.33 ]} >>> ) def v2 = | json_emitter() . every ( 3s ) . json ( <<< { \"condition\" : { \"id1\" : 0 , \"name1\" : \"OK\" , \"sub_cond\" : [{ \"number\" : 44 }]}, \"condition_reason\" : \"\" , \"predicted_maintenance_time\" : 1584246411783 , \"vac_on_without_contact\" : [ 2.2 , 2.5 , 4.33 ], \"vac_on_with_contact\" : [ 5.6 , 45.98 , 7.012 ]} >>> ) v1 | join( v2 ) . field_merge ( 'data' ) . tolerance ( 20ms ) . missing_timeout ( 30ms ) . fill ( null ) | debug() v1 node data-field (in json format for readability): { \"condition\" : { \"id\" : 0 , \"name\" : \"OK\" , \"sub_cond\" : [{ \"value\" : 33 }]}, \"condition_reason\" : \"Reason\" , \"predicted_maintenance_time\" : 1584246411783 , \"vac_on_without_contact\" : [ 1.2 , 2.5 , 4.33 ] } v2 node data-field: { \"condition\" : { \"id1\" : 0 , \"name1\" : \"OK\" , \"sub_cond\" : [{ \"number\" : 44 }]}, \"condition_reason\" : \"\" , \"predicted_maintenance_time\" : 1584246411785 , \"vac_on_without_contact\" : [ 2.2 , 2.5 , 4.33 ], \"vac_on_with_contact\" : [ 5.6 , 45.98 , 7.012 ] } The result data-field after merge (json format here): { \"condition\" : { \"name1\" : \"OK\" , \"name\" : \"OK\" , \"id1\" : 0 , \"id\" : 0 , \"sub_cond\" :[{ \"number\" : 44 }, { \"value\" : 33 }] }, \"predicted_maintenance_time\" : 1584246411785 , \"vac_on_without_contact\" :[ 1.2 , 2.2 , 2.5 , 2.5 , 4.33 , 4.33 ], \"vac_on_with_contact\" :[ 5.6 , 45.98 , 7.012 ], \"condition_reason\" : \"\" } Objects and lists and lists of objects will be merged. If a path exists in several streams, the value in the first stream is superseded by the value in a following stream (\"condition_reason\" and \"predicted_maintenance_time\" in this example). Except for lists, which will be merged (\"vac_on_without_contact\").","title":"Join"},{"location":"nodes/join.html#the-join-node","text":"Join data from two or more nodes, given a list of prefixes, for each row. If the field_merge parameter is given, the node will merge the field given from every in-node, instead of joining. When considering the fill option, the following rules apply: 'none' - (default) skip rows where a point is missing, inner join. 'null' - fill missing points with null, full outer join. Any value - fill fields with given value, full outer join. Note, that this node will produce a completely new stream.","title":"The join node"},{"location":"nodes/join.html#example","text":"def v1 = | value_emitter() . every ( 3s ) . type ( point ) . align () def v2 = | value_emitter() . every ( 5s ) . type ( point ) . align () v1 | join( v2 ) . prefix ( 'v1.joined' , 'v2.joined' ) . tolerance ( 3s ) . missing_timeout ( 3s ) . fill ( none ) Joins the fields of v1 and v2 and produces a stream, that has the fields v1.joined.val and v2.joined.val","title":"Example"},{"location":"nodes/join.html#node-parameters","text":"Parameter Description Default nodes( node_list ) list of node (chains) to merge []","title":"Node Parameters"},{"location":"nodes/join.html#parameters","text":"Parameter Description Default prefix( string_list ) list of prefixes (used in join mode) ['', ''] (no prefixes) field_merge( string ) when given, the join node will do a field merge operation undefined missing_timeout( duration ) values that do not arrive within this timeout will be treated as missing 20s tolerance( duration ) db fieldnames (mapping for faxe fieldname to table field names) fill( 'none' 'null' any ) fill missing values / join behaviour 'none'","title":"Parameters"},{"location":"nodes/join.html#merge-example","text":"Let's look at an example where the streams coming out of two nodes are not joined with prefixes, but a merge operation is performed. def v1 = | json_emitter() . every ( 3s ) . json ( <<< { \"condition\" : { \"id\" : 0 , \"name\" : \"OK\" , \"sub_cond\" : [{ \"value\" : 33 }]}, \"condition_reason\" : \"\" , \"predicted_maintenance_time\" : 1584246411783 , \"vac_on_without_contact\" : [ 1.2 , 2.5 , 4.33 ]} >>> ) def v2 = | json_emitter() . every ( 3s ) . json ( <<< { \"condition\" : { \"id1\" : 0 , \"name1\" : \"OK\" , \"sub_cond\" : [{ \"number\" : 44 }]}, \"condition_reason\" : \"\" , \"predicted_maintenance_time\" : 1584246411783 , \"vac_on_without_contact\" : [ 2.2 , 2.5 , 4.33 ], \"vac_on_with_contact\" : [ 5.6 , 45.98 , 7.012 ]} >>> ) v1 | join( v2 ) . field_merge ( 'data' ) . tolerance ( 20ms ) . missing_timeout ( 30ms ) . fill ( null ) | debug()","title":"Merge example"},{"location":"nodes/join.html#v1-node-data-field-in-json-format-for-readability","text":"{ \"condition\" : { \"id\" : 0 , \"name\" : \"OK\" , \"sub_cond\" : [{ \"value\" : 33 }]}, \"condition_reason\" : \"Reason\" , \"predicted_maintenance_time\" : 1584246411783 , \"vac_on_without_contact\" : [ 1.2 , 2.5 , 4.33 ] }","title":"v1 node data-field (in json format for readability):"},{"location":"nodes/join.html#v2-node-data-field","text":"{ \"condition\" : { \"id1\" : 0 , \"name1\" : \"OK\" , \"sub_cond\" : [{ \"number\" : 44 }]}, \"condition_reason\" : \"\" , \"predicted_maintenance_time\" : 1584246411785 , \"vac_on_without_contact\" : [ 2.2 , 2.5 , 4.33 ], \"vac_on_with_contact\" : [ 5.6 , 45.98 , 7.012 ] } The result data-field after merge (json format here): { \"condition\" : { \"name1\" : \"OK\" , \"name\" : \"OK\" , \"id1\" : 0 , \"id\" : 0 , \"sub_cond\" :[{ \"number\" : 44 }, { \"value\" : 33 }] }, \"predicted_maintenance_time\" : 1584246411785 , \"vac_on_without_contact\" :[ 1.2 , 2.2 , 2.5 , 2.5 , 4.33 , 4.33 ], \"vac_on_with_contact\" :[ 5.6 , 45.98 , 7.012 ], \"condition_reason\" : \"\" } Objects and lists and lists of objects will be merged. If a path exists in several streams, the value in the first stream is superseded by the value in a following stream (\"condition_reason\" and \"predicted_maintenance_time\" in this example). Except for lists, which will be merged (\"vac_on_without_contact\").","title":"v2 node data-field:"},{"location":"nodes/json_emitter.html","text":"The json_emitter node This node is for debugging and testing/mocking purposes. It periodically emits one of the json strings given with the json parameter. Example | json_emitter() . every ( 3s ) . json ( <<< {\"condition\": {\"id\": 0, \"name\": \"OK\"}, \"condition_reason\": \"\", \"predicted_maintenance_time\": 1584246411783, \"vac_on_without_contact\": [1.2, 2.5, 4.33], \"vac_on_with_contact\": [5.6, 45.98, 7.012]} >>>, <<< {\"condition\": {\"id\": 1, \"name\": \"Warning\"}, \"condition_reason\": \"bad succer\", \"predicted_maintenance_time\": 1583246411783, \"vac_on_without_contact\": [0.2, 2.5, 8.01], \"vac_on_with_contact\": [6.001, 4.798, 7.012]} >>>, <<< {\"condition\": {\"id\": 2, \"name\": \"Error\"}, \"condition_reason\": \"something went really wrong!\", \"predicted_maintenance_time\": 1582246411783, \"vac_on_without_contact\": [0.5, 2.5, 0.44], \"vac_on_with_contact\": [2.06, 4.98, 2.901]} >>> ) | debug() Emit one of the three given json strings(selected randomly) every 3 seconds. Parameters Parameter Description Default every( duration ) emit interval 5s jitter( duration ) add time jitter to the values produced 0ms json( string_list ) list of json strings align( is_set ) align the time to the every param false (not set)","title":"Json emitter"},{"location":"nodes/json_emitter.html#the-json_emitter-node","text":"This node is for debugging and testing/mocking purposes. It periodically emits one of the json strings given with the json parameter.","title":"The json_emitter node"},{"location":"nodes/json_emitter.html#example","text":"| json_emitter() . every ( 3s ) . json ( <<< {\"condition\": {\"id\": 0, \"name\": \"OK\"}, \"condition_reason\": \"\", \"predicted_maintenance_time\": 1584246411783, \"vac_on_without_contact\": [1.2, 2.5, 4.33], \"vac_on_with_contact\": [5.6, 45.98, 7.012]} >>>, <<< {\"condition\": {\"id\": 1, \"name\": \"Warning\"}, \"condition_reason\": \"bad succer\", \"predicted_maintenance_time\": 1583246411783, \"vac_on_without_contact\": [0.2, 2.5, 8.01], \"vac_on_with_contact\": [6.001, 4.798, 7.012]} >>>, <<< {\"condition\": {\"id\": 2, \"name\": \"Error\"}, \"condition_reason\": \"something went really wrong!\", \"predicted_maintenance_time\": 1582246411783, \"vac_on_without_contact\": [0.5, 2.5, 0.44], \"vac_on_with_contact\": [2.06, 4.98, 2.901]} >>> ) | debug() Emit one of the three given json strings(selected randomly) every 3 seconds.","title":"Example"},{"location":"nodes/json_emitter.html#parameters","text":"Parameter Description Default every( duration ) emit interval 5s jitter( duration ) add time jitter to the values produced 0ms json( string_list ) list of json strings align( is_set ) align the time to the every param false (not set)","title":"Parameters"},{"location":"nodes/keep.html","text":"The keep node Keep only those fields and tags specified by the parameters. Example | keep() . fields ( 'data.topic' , 'data.temperature' ) . as ( 'topic' , 'temperature' ) Parameters Parameter Description Default fields( string_list ) list of fieldnames to keep from the incoming data [] tags( string_list ) list of tagnames to keep from the incoming data [] as( string_list ) list of new field names for the kept fields, if given, must have the same count of names as fields []","title":"Keep"},{"location":"nodes/keep.html#the-keep-node","text":"Keep only those fields and tags specified by the parameters.","title":"The keep node"},{"location":"nodes/keep.html#example","text":"| keep() . fields ( 'data.topic' , 'data.temperature' ) . as ( 'topic' , 'temperature' )","title":"Example"},{"location":"nodes/keep.html#parameters","text":"Parameter Description Default fields( string_list ) list of fieldnames to keep from the incoming data [] tags( string_list ) list of tagnames to keep from the incoming data [] as( string_list ) list of new field names for the kept fields, if given, must have the same count of names as fields []","title":"Parameters"},{"location":"nodes/log.html","text":"The log node Log incoming data to a file in json format (line by line) Example | log() . file ( 'topics.txt' ) Parameters Parameter Description Default file( string ) valid writeable filepath","title":"Log"},{"location":"nodes/log.html#the-log-node","text":"Log incoming data to a file in json format (line by line)","title":"The log node"},{"location":"nodes/log.html#example","text":"| log() . file ( 'topics.txt' )","title":"Example"},{"location":"nodes/log.html#parameters","text":"Parameter Description Default file( string ) valid writeable filepath","title":"Parameters"},{"location":"nodes/mem.html","text":"The mem node Flow wide value storage. mem values are available to any other node (in lambda expressions) within a flow. There are 3 types of memories: 'single' holds a single value 'list' holds a list of values, value order is preserved within the list 'set' holds a list of values, where values have not duplicates The values will be held in an non persistent ets term storage. Example | mem() . type ( 'set' ) . field ( 'topic' ) . key ( 'topics_seen' ) Holds a set of values from the field named topic . The set of values is available in lambda expression (within the same flow) with the key topics_seen . The above set can be used in lambda expressions with the functions: ls_mem , ls_mem_list , ls_mem_set . |where(lambda: if( member(\"topic\", ls_mem_set('topics_seen')), false, true) ) This will filter out all points that have a topic field, which has already be stored in the mem set. Thus the where node will only output points with a unique topic value. Parameters Parameter Description Default field( string ) field-path key( string ) name of the value storage type( string ) Type of mem storage, one of 'single', 'list' or 'set' 'single'","title":"Mem"},{"location":"nodes/mem.html#the-mem-node","text":"Flow wide value storage. mem values are available to any other node (in lambda expressions) within a flow. There are 3 types of memories: 'single' holds a single value 'list' holds a list of values, value order is preserved within the list 'set' holds a list of values, where values have not duplicates The values will be held in an non persistent ets term storage.","title":"The mem node"},{"location":"nodes/mem.html#example","text":"| mem() . type ( 'set' ) . field ( 'topic' ) . key ( 'topics_seen' ) Holds a set of values from the field named topic . The set of values is available in lambda expression (within the same flow) with the key topics_seen . The above set can be used in lambda expressions with the functions: ls_mem , ls_mem_list , ls_mem_set . |where(lambda: if( member(\"topic\", ls_mem_set('topics_seen')), false, true) ) This will filter out all points that have a topic field, which has already be stored in the mem set. Thus the where node will only output points with a unique topic value.","title":"Example"},{"location":"nodes/mem.html#parameters","text":"Parameter Description Default field( string ) field-path key( string ) name of the value storage type( string ) Type of mem storage, one of 'single', 'list' or 'set' 'single'","title":"Parameters"},{"location":"nodes/modbus.html","text":"The modbus node Pull data via modbus tcp, supported read functions are : ['coils', 'hregs', 'iregs', 'inputs', 'memory'] Read multiple values with possibly different functions at once If the align property is set, the nodes's read times will be truncated to the every property (For example, if the node is started at 12:06 and the every property is 5m then the next read will occur at 12:10, then the next at 12:15 and so on, instead of 12:06, 12:11 and so on). Example | modbus() . ip ( '127.0.0.1' ) . device ( 255 ) . every ( 1s ) . function ( 'coils' , 'hregs' , 'iregs' ) . from ( 2127 , 3008 , 104 ) . count ( 1 , 2 , 2 ) . as ( 'Energy.EnergyConsumption' , 'Energy.CurrentValue' , 'Energy.EnergyDelivered' ) . output ( 'int16' , 'float32' , 'float32' ) . signed ( true , true , false ) Parameters Parameter Description Default ip( string ) ip address of modbus device port( integer ) port of modbus device 502 every( duration ) time between reads 1s align( is_set ) align read intervals according to every false (not set) device( integer ) modbus device id (0-255) 255 function( string_list ) list of read functions, one of ['coils', 'hregs', 'iregs', 'inputs', 'memory'] from( integer_list ) list of start values count( integer_list ) list of count values, how much data to read for every function given as( string_list ) output names for the read values output( string_list ) list of output formats one of ['int16', 'int32', 'float32', 'coils', 'ascii', 'binary'] undefined signed( atom_list true/false) list of values indicating if values are signed undefined Note that, if given, all read parameters( function, from, count, as, output, signed ) must have the same length, this means if you have two values you want to read -> .function('coils', 'hregs') all corresponding read params must have the same length -> .as('val1', 'val2').output(int16, float32).from(1,2).count(2,4).signed(true, true)","title":"Modbus"},{"location":"nodes/modbus.html#the-modbus-node","text":"Pull data via modbus tcp, supported read functions are : ['coils', 'hregs', 'iregs', 'inputs', 'memory'] Read multiple values with possibly different functions at once If the align property is set, the nodes's read times will be truncated to the every property (For example, if the node is started at 12:06 and the every property is 5m then the next read will occur at 12:10, then the next at 12:15 and so on, instead of 12:06, 12:11 and so on).","title":"The modbus node"},{"location":"nodes/modbus.html#example","text":"| modbus() . ip ( '127.0.0.1' ) . device ( 255 ) . every ( 1s ) . function ( 'coils' , 'hregs' , 'iregs' ) . from ( 2127 , 3008 , 104 ) . count ( 1 , 2 , 2 ) . as ( 'Energy.EnergyConsumption' , 'Energy.CurrentValue' , 'Energy.EnergyDelivered' ) . output ( 'int16' , 'float32' , 'float32' ) . signed ( true , true , false )","title":"Example"},{"location":"nodes/modbus.html#parameters","text":"Parameter Description Default ip( string ) ip address of modbus device port( integer ) port of modbus device 502 every( duration ) time between reads 1s align( is_set ) align read intervals according to every false (not set) device( integer ) modbus device id (0-255) 255 function( string_list ) list of read functions, one of ['coils', 'hregs', 'iregs', 'inputs', 'memory'] from( integer_list ) list of start values count( integer_list ) list of count values, how much data to read for every function given as( string_list ) output names for the read values output( string_list ) list of output formats one of ['int16', 'int32', 'float32', 'coils', 'ascii', 'binary'] undefined signed( atom_list true/false) list of values indicating if values are signed undefined Note that, if given, all read parameters( function, from, count, as, output, signed ) must have the same length, this means if you have two values you want to read -> .function('coils', 'hregs') all corresponding read params must have the same length -> .as('val1', 'val2').output(int16, float32).from(1,2).count(2,4).signed(true, true)","title":"Parameters"},{"location":"nodes/mqtt_publish.html","text":"The mqtt_publish node Publish data to an mqtt-broker. Incoming data is converted to JSON before sending. If the save() parameter is given, every message first gets stored to an on-disk queue before sending, this way we can make sure no message gets lost when disconnected from the broker. Example def topic = 'top/track/pressure' | mqtt_publish() . topic ( topic ) . retained () Using a lambda expression for the topic: def topic_base = 'top/' | mqtt_publish() . topic_lambda ( lambda : str_concat ([ topic_base , \"type\" , '/' , \"measurement\" ]) Here the topic string is built with a lambda expression using the topic_base declaration, the string '/' and two fields from the current data_point. The topic string may be a different one with every data_point that gets published. Parameters Parameter Description Default host( string ) Ip address or hostname of the broker from config file port( integer ) The broker's port 1883 from config file topic( string ) mqtt topic to use topic_lambda( lambda ) mqtt topic to use evaluated via a lambda expression qos( integer ) Quality of service, one of 0, 1 or 2 1 retained( is_set ) whether the message should be retained on the broker false (not set) save( is_set ) send save (on-disk queuing) false (not set) ssl( is_set ) whether to use ssl false (not set) topic or topic_lambda must be provided.","title":"Mqtt publish"},{"location":"nodes/mqtt_publish.html#the-mqtt_publish-node","text":"Publish data to an mqtt-broker. Incoming data is converted to JSON before sending. If the save() parameter is given, every message first gets stored to an on-disk queue before sending, this way we can make sure no message gets lost when disconnected from the broker.","title":"The mqtt_publish node"},{"location":"nodes/mqtt_publish.html#example","text":"def topic = 'top/track/pressure' | mqtt_publish() . topic ( topic ) . retained () Using a lambda expression for the topic: def topic_base = 'top/' | mqtt_publish() . topic_lambda ( lambda : str_concat ([ topic_base , \"type\" , '/' , \"measurement\" ]) Here the topic string is built with a lambda expression using the topic_base declaration, the string '/' and two fields from the current data_point. The topic string may be a different one with every data_point that gets published.","title":"Example"},{"location":"nodes/mqtt_publish.html#parameters","text":"Parameter Description Default host( string ) Ip address or hostname of the broker from config file port( integer ) The broker's port 1883 from config file topic( string ) mqtt topic to use topic_lambda( lambda ) mqtt topic to use evaluated via a lambda expression qos( integer ) Quality of service, one of 0, 1 or 2 1 retained( is_set ) whether the message should be retained on the broker false (not set) save( is_set ) send save (on-disk queuing) false (not set) ssl( is_set ) whether to use ssl false (not set) topic or topic_lambda must be provided.","title":"Parameters"},{"location":"nodes/mqtt_subscribe.html","text":"The mqtt_subscribe node Subscribe to an mqtt-broker and get data from one or more topics. Example | mqtt_subscribe() . topics ( 'top/grips/#' ) . dt_field ( 'UTC-Stamp' ) . dt_format ( 'float_micro' ) Parameters Parameter Description Default host( string ) Ip address or hostname of the broker from config file port( integer ) The broker's port 1883 from config file topics( string_list ) mqtt topic to use qos( integer ) Quality of service, one of 0, 1 or 2 1 retained( is_set ) whether the message should be retained on the broker false (not set) dt_field( string ) name of the timestamp field that is expected 'ts' dt_format( string ) timestamp or datetime format that is expected (see table below) 'millisecond' ssl( is_set ) whether to use ssl false (not set) Available datetime formats dt_format description example 'millisecond' timestamp UTC in milliseconds 1565343079000 'second' timestamp UTC in seconds 1565343079 'float_micro' timestamp UTC float with microsecond precision 1565343079.173588 'float_millisecond' timestamp UTC float with millisecond precision 1565343079.173 'ISO8601' ISO8601 Datetime format string '2011-10-05T14:48:00.000Z' 'RFC3339' RFC3339 Datetime format string '2018-02-01 15:18:02.088Z' 'convtrack_datetime' special datetime format used in the conveyor tracking data stream '19.08.01 17:33:44,867 '","title":"Mqtt subscribe"},{"location":"nodes/mqtt_subscribe.html#the-mqtt_subscribe-node","text":"Subscribe to an mqtt-broker and get data from one or more topics.","title":"The mqtt_subscribe node"},{"location":"nodes/mqtt_subscribe.html#example","text":"| mqtt_subscribe() . topics ( 'top/grips/#' ) . dt_field ( 'UTC-Stamp' ) . dt_format ( 'float_micro' )","title":"Example"},{"location":"nodes/mqtt_subscribe.html#parameters","text":"Parameter Description Default host( string ) Ip address or hostname of the broker from config file port( integer ) The broker's port 1883 from config file topics( string_list ) mqtt topic to use qos( integer ) Quality of service, one of 0, 1 or 2 1 retained( is_set ) whether the message should be retained on the broker false (not set) dt_field( string ) name of the timestamp field that is expected 'ts' dt_format( string ) timestamp or datetime format that is expected (see table below) 'millisecond' ssl( is_set ) whether to use ssl false (not set)","title":"Parameters"},{"location":"nodes/mqtt_subscribe.html#available-datetime-formats","text":"dt_format description example 'millisecond' timestamp UTC in milliseconds 1565343079000 'second' timestamp UTC in seconds 1565343079 'float_micro' timestamp UTC float with microsecond precision 1565343079.173588 'float_millisecond' timestamp UTC float with millisecond precision 1565343079.173 'ISO8601' ISO8601 Datetime format string '2011-10-05T14:48:00.000Z' 'RFC3339' RFC3339 Datetime format string '2018-02-01 15:18:02.088Z' 'convtrack_datetime' special datetime format used in the conveyor tracking data stream '19.08.01 17:33:44,867 '","title":"Available datetime formats"},{"location":"nodes/oracle_query.html","text":"The oracle_query node Used to batch a number of points. As soon as the node has collected size points it will emit them in a data_batch. A timeout can be set, after which all points currently in the buffer will be emitted, regardless of the number of collected points. The timeout is started on the first datapoint coming in to an empty buffer. Example | batch( 12 ) | batch( 5 ) . timeout ( 3s ) The second example will output a batch with 5 points. If the points come in within 3 seconds the node will emit them in a databatch and reset the timeout. If after 3 seconds there are less than 5 points in the buffer, the node will emit them, regardless of the number. Parameters Parameter Description Default [node] size( integer ) Number of points to batch timeout( duration ) Previous values TTL optional","title":"Oracle query"},{"location":"nodes/oracle_query.html#the-oracle_query-node","text":"Used to batch a number of points. As soon as the node has collected size points it will emit them in a data_batch. A timeout can be set, after which all points currently in the buffer will be emitted, regardless of the number of collected points. The timeout is started on the first datapoint coming in to an empty buffer.","title":"The oracle_query node"},{"location":"nodes/oracle_query.html#example","text":"| batch( 12 ) | batch( 5 ) . timeout ( 3s ) The second example will output a batch with 5 points. If the points come in within 3 seconds the node will emit them in a databatch and reset the timeout. If after 3 seconds there are less than 5 points in the buffer, the node will emit them, regardless of the number.","title":"Example"},{"location":"nodes/oracle_query.html#parameters","text":"Parameter Description Default [node] size( integer ) Number of points to batch timeout( duration ) Previous values TTL optional","title":"Parameters"},{"location":"nodes/python.html","text":"The python node Rules for python callback classes: Callback class must be in a module with the lowercase name of the class ie: module: \"double\", class: \"Double\" python callback class must be a subclass of the class Faxe from module faxe 'abstract' methods to implement are (note: they are all optional ): options() -> return a list of tuples // static init(self, args ) -> gets the object and a dict with args from options() handle_point(self, point_data) -> point_data is a dict handle_batch(self, batch_data ) -> batch_data is a list of dicts (points) the callbacks need not return anything except for the options method to emit data the method self.emit(data) has to be used, where data is a dict or a list of dicts A custom python node is used with an @ as node sign instead of | in dfs! @ my_custom_python_node () Parameters Parameters can be freely defined by the python callback class via the static options() method (See example blow). Note that parameter definition must be in bytes type. Example Callback The example python callback class below defined 2 Parameters: field must be a string and has no default value (so it must be given) as must be a string and has the default value 'double' from faxe import Faxe class Double (Faxe): @staticmethod def options (): \"\"\" overwrite this method to request options you would like to use return value is a list of tuples: (option_name, option_type, (optional: default type)) a two tuple: (b\"foo\", b\"string\") with no default value is mandatory in the dfs script a three tuple: (b\"foo\", b\"string\", b\"mystring\") may be overwritten in a dfs script :return: list of tuples \"\"\" opts = [ ( b'field' , b'string' ), ( b'as' , b'string' , b'double' ) ] return opts def init (self, args): \"\"\" will be called on startup with args requested with options() :param args: dict \"\"\" self . fieldname = args[ b'field' ] self . asfieldname = args[ b'as' ] print ( \"my args: \" , args) def handle_point (self, point_data): \"\"\" called when a data_point comes in to this node :param point_data: dict \"\"\" self . emit(self . calc(point_data)) def handle_batch (self, batch_data): \"\"\" called when a data_batch comes in :param batch_data: list of dicts \"\"\" out_list = list() for point in batch_data: out_list . append(self . calc(point)) self . emit(out_list) def calc (self, point_dict): point_dict[self . asfieldname] = point_dict[self . fieldname] * 2 return point_dict Use in a dfs script: @ double () . field ( 'val' ) . as ( 'double_val' )","title":"Python"},{"location":"nodes/python.html#the-python-node","text":"Rules for python callback classes: Callback class must be in a module with the lowercase name of the class ie: module: \"double\", class: \"Double\" python callback class must be a subclass of the class Faxe from module faxe 'abstract' methods to implement are (note: they are all optional ): options() -> return a list of tuples // static init(self, args ) -> gets the object and a dict with args from options() handle_point(self, point_data) -> point_data is a dict handle_batch(self, batch_data ) -> batch_data is a list of dicts (points) the callbacks need not return anything except for the options method to emit data the method self.emit(data) has to be used, where data is a dict or a list of dicts A custom python node is used with an @ as node sign instead of | in dfs! @ my_custom_python_node ()","title":"The python node"},{"location":"nodes/python.html#parameters","text":"Parameters can be freely defined by the python callback class via the static options() method (See example blow). Note that parameter definition must be in bytes type.","title":"Parameters"},{"location":"nodes/python.html#example-callback","text":"The example python callback class below defined 2 Parameters: field must be a string and has no default value (so it must be given) as must be a string and has the default value 'double' from faxe import Faxe class Double (Faxe): @staticmethod def options (): \"\"\" overwrite this method to request options you would like to use return value is a list of tuples: (option_name, option_type, (optional: default type)) a two tuple: (b\"foo\", b\"string\") with no default value is mandatory in the dfs script a three tuple: (b\"foo\", b\"string\", b\"mystring\") may be overwritten in a dfs script :return: list of tuples \"\"\" opts = [ ( b'field' , b'string' ), ( b'as' , b'string' , b'double' ) ] return opts def init (self, args): \"\"\" will be called on startup with args requested with options() :param args: dict \"\"\" self . fieldname = args[ b'field' ] self . asfieldname = args[ b'as' ] print ( \"my args: \" , args) def handle_point (self, point_data): \"\"\" called when a data_point comes in to this node :param point_data: dict \"\"\" self . emit(self . calc(point_data)) def handle_batch (self, batch_data): \"\"\" called when a data_batch comes in :param batch_data: list of dicts \"\"\" out_list = list() for point in batch_data: out_list . append(self . calc(point)) self . emit(out_list) def calc (self, point_dict): point_dict[self . asfieldname] = point_dict[self . fieldname] * 2 return point_dict Use in a dfs script: @ double () . field ( 'val' ) . as ( 'double_val' )","title":"Example Callback"},{"location":"nodes/rename.html","text":"The rename node Rename existing fields and/or tags. Example | rename() . fields ( 'topic' , 'temperature' ) . as_fields ( 'cipot' , 'mean_temp' ) Parameters Parameter Description Default fields( string_list ) list of fieldnames to rename [] as_fields( string_list ) list of new fieldnames for renaming [] tags( string_list ) list of tagnames to rename [] as_tags( string_list ) list of new tagnames for renaming []","title":"Rename"},{"location":"nodes/rename.html#the-rename-node","text":"Rename existing fields and/or tags.","title":"The rename node"},{"location":"nodes/rename.html#example","text":"| rename() . fields ( 'topic' , 'temperature' ) . as_fields ( 'cipot' , 'mean_temp' )","title":"Example"},{"location":"nodes/rename.html#parameters","text":"Parameter Description Default fields( string_list ) list of fieldnames to rename [] as_fields( string_list ) list of new fieldnames for renaming [] tags( string_list ) list of tagnames to rename [] as_tags( string_list ) list of new tagnames for renaming []","title":"Parameters"},{"location":"nodes/s7poll.html","text":"The s7poll node Periodically pull data from a siemens s7 plc via the snap7 library using the iso on tcp protocol . Data addressing can be done in a Step7 schema or with a sligthly different schema used in node-red (although the step7 variant is preferred). See table below for more information. Note: max 19 values can be read with one s7poll node at the moment. Example | s7poll() . ip ( 10.10.204.15 ) . port ( 102 ) . rack ( 0 ) . slot ( 2 ) . every ( 3s ) . vars ( 'DB1140.DBX4.0' , 'DB1140.DBX4.1' , 'DB1140.DBX4.4' , 'DB1140.DBX4.5' ) . as ( 'data.tbo[1].ix_OcM1' , 'data.tbo[1].ix_OcM2' , 'data.tbo[1].ix_Lift_PosTop' , 'data.tbo[1].ix_Lift_PosBo' ) Read 4 values (BOOL in this case) from a plc every 3 seconds and name them with a deep json path. Parameters Parameter Description Default ip( string ) ip address of plc port( integer ) port of modbus device 102 every( duration ) time between reads 1s align( is_set ) align read intervals according to every false (not set) slot( integer ) plc slot number 0 rack( integer ) plc rack number 0 vars( string_list ) list of s7 addresses ie: 'DB3.DBX2.5' (see table below) as( string_list ) output names for the read values diff( is_set ) when given, only output values different to previous values false (not set) Note that params vars and as must have the same length. Data addressing Note: Step7 style preferred and should be used ! Address Step7 equivalent JS Data type Description DB5,X0.1 DB5.DBX0.1 Boolean Bit 1 of byte 0 of DB 5 DB23,B1 or DB23,BYTE1 DB23.DBB1 Number Byte 1 (0-255) of DB 23 DB100,C2 or DB100,CHAR2 DB100.DBB2 String Byte 2 of DB 100 as a Char DB42,I3 or DB42,INT3 DB42.DBW3 Number Signed 16-bit number at byte 3 of DB 42 DB57,WORD4 DB57.DBW4 Number Unsigned 16-bit number at byte 4 of DB 57 DB13,DI5 or DB13,DINT5 DB13.DBD5 Number Signed 32-bit number at byte 5 of DB 13 DB19,DW6 or DB19,DWORD6 DB19.DBD6 Number Unsigned 32-bit number at byte 6 of DB 19 DB21,DR7 or DB21,REAL7 DB19.DBD6 Number Floating point 32-bit number at byte 7 of DB 21 DB2,S7.10* - String String of length 10 starting at byte 7 of DB 2 I1.0 or E1.0 I1.0 or E1.0 Boolean Bit 0 of byte 1 of input area Q2.1 or A2.1 Q2.1 or A2.1 Boolean Bit 1 of byte 2 of output area M3.2 QM3.2 Boolean Bit 2 of byte 3 of memory area IB4 or EB4 IB4 or EB4 Number Byte 4 (0 -255) of input area QB5 or AB5 QB5 or AB5 Number Byte 5 (0 -255) of output area MB6 MB6 Number Byte 6 (0 -255) of memory area IC7 or EC7 IB7 or EB7 String Byte 7 of input area as a Char QC8 or AC8 QB8 or AB8 String Byte 8 of output area as a Char MC9 MB9 String Byte 9 of memory area as a Char II10 or EI10 IW10 or EW10 Number Signed 16-bit number at byte 10 of input area QI12 or AI12 QW12 or AW12 Number Signed 16-bit number at byte 12 of output area MI14 MW14 Number Signed 16-bit number at byte 14 of memory area IW16 or EW16 IW16 or EW16 Number Unsigned 16-bit number at byte 16 of input area QW18 or AW18 QW18 or AW18 Number Unsigned 16-bit number at byte 18 of output area MW20 MW20 Number Unsigned 16-bit number at byte 20 of memory area IDI22 or EDI22 ID22 or ED22 Number Signed 32-bit number at byte 22 of input area QDI24 or ADI24 QD24 or AD24 Number Signed 32-bit number at byte 24 of output area MDI26 MD26 Number Signed 32-bit number at byte 26 of memory area ID28 or ED28 ID28 or ED28 Number Unsigned 32-bit number at byte 28 of input area QD30 or AD30 QD30 or AD30 Number Unsigned 32-bit number at byte 30 of output area MD32 MD32 Number Unsigned 32-bit number at byte 32 of memory area IR34 or ER34 IR34 or ER34 Number Floating point 32-bit number at byte 34 of input area QR36 or AR36 QR36 or AR36 Number Floating point 32-bit number at byte 36 of output area MR38 MR38 Number Floating point 32-bit number at byte 38 of memory area","title":"S7poll"},{"location":"nodes/s7poll.html#the-s7poll-node","text":"Periodically pull data from a siemens s7 plc via the snap7 library using the iso on tcp protocol . Data addressing can be done in a Step7 schema or with a sligthly different schema used in node-red (although the step7 variant is preferred). See table below for more information. Note: max 19 values can be read with one s7poll node at the moment.","title":"The s7poll node"},{"location":"nodes/s7poll.html#example","text":"| s7poll() . ip ( 10.10.204.15 ) . port ( 102 ) . rack ( 0 ) . slot ( 2 ) . every ( 3s ) . vars ( 'DB1140.DBX4.0' , 'DB1140.DBX4.1' , 'DB1140.DBX4.4' , 'DB1140.DBX4.5' ) . as ( 'data.tbo[1].ix_OcM1' , 'data.tbo[1].ix_OcM2' , 'data.tbo[1].ix_Lift_PosTop' , 'data.tbo[1].ix_Lift_PosBo' ) Read 4 values (BOOL in this case) from a plc every 3 seconds and name them with a deep json path.","title":"Example"},{"location":"nodes/s7poll.html#parameters","text":"Parameter Description Default ip( string ) ip address of plc port( integer ) port of modbus device 102 every( duration ) time between reads 1s align( is_set ) align read intervals according to every false (not set) slot( integer ) plc slot number 0 rack( integer ) plc rack number 0 vars( string_list ) list of s7 addresses ie: 'DB3.DBX2.5' (see table below) as( string_list ) output names for the read values diff( is_set ) when given, only output values different to previous values false (not set) Note that params vars and as must have the same length.","title":"Parameters"},{"location":"nodes/s7poll.html#data-addressing","text":"Note: Step7 style preferred and should be used ! Address Step7 equivalent JS Data type Description DB5,X0.1 DB5.DBX0.1 Boolean Bit 1 of byte 0 of DB 5 DB23,B1 or DB23,BYTE1 DB23.DBB1 Number Byte 1 (0-255) of DB 23 DB100,C2 or DB100,CHAR2 DB100.DBB2 String Byte 2 of DB 100 as a Char DB42,I3 or DB42,INT3 DB42.DBW3 Number Signed 16-bit number at byte 3 of DB 42 DB57,WORD4 DB57.DBW4 Number Unsigned 16-bit number at byte 4 of DB 57 DB13,DI5 or DB13,DINT5 DB13.DBD5 Number Signed 32-bit number at byte 5 of DB 13 DB19,DW6 or DB19,DWORD6 DB19.DBD6 Number Unsigned 32-bit number at byte 6 of DB 19 DB21,DR7 or DB21,REAL7 DB19.DBD6 Number Floating point 32-bit number at byte 7 of DB 21 DB2,S7.10* - String String of length 10 starting at byte 7 of DB 2 I1.0 or E1.0 I1.0 or E1.0 Boolean Bit 0 of byte 1 of input area Q2.1 or A2.1 Q2.1 or A2.1 Boolean Bit 1 of byte 2 of output area M3.2 QM3.2 Boolean Bit 2 of byte 3 of memory area IB4 or EB4 IB4 or EB4 Number Byte 4 (0 -255) of input area QB5 or AB5 QB5 or AB5 Number Byte 5 (0 -255) of output area MB6 MB6 Number Byte 6 (0 -255) of memory area IC7 or EC7 IB7 or EB7 String Byte 7 of input area as a Char QC8 or AC8 QB8 or AB8 String Byte 8 of output area as a Char MC9 MB9 String Byte 9 of memory area as a Char II10 or EI10 IW10 or EW10 Number Signed 16-bit number at byte 10 of input area QI12 or AI12 QW12 or AW12 Number Signed 16-bit number at byte 12 of output area MI14 MW14 Number Signed 16-bit number at byte 14 of memory area IW16 or EW16 IW16 or EW16 Number Unsigned 16-bit number at byte 16 of input area QW18 or AW18 QW18 or AW18 Number Unsigned 16-bit number at byte 18 of output area MW20 MW20 Number Unsigned 16-bit number at byte 20 of memory area IDI22 or EDI22 ID22 or ED22 Number Signed 32-bit number at byte 22 of input area QDI24 or ADI24 QD24 or AD24 Number Signed 32-bit number at byte 24 of output area MDI26 MD26 Number Signed 32-bit number at byte 26 of memory area ID28 or ED28 ID28 or ED28 Number Unsigned 32-bit number at byte 28 of input area QD30 or AD30 QD30 or AD30 Number Unsigned 32-bit number at byte 30 of output area MD32 MD32 Number Unsigned 32-bit number at byte 32 of memory area IR34 or ER34 IR34 or ER34 Number Floating point 32-bit number at byte 34 of input area QR36 or AR36 QR36 or AR36 Number Floating point 32-bit number at byte 36 of output area MR38 MR38 Number Floating point 32-bit number at byte 38 of memory area","title":"Data addressing"},{"location":"nodes/sample.html","text":"The sample node Samples the incoming points or batches. One point will be emitted every count ~~or duration~~ specified. Note: time based sampling is not supported with this version Example | sample( 5 ) Keep every 5th data_point or data_batch. ~~| sample( 10s ) ~~ ~~Keep every point or batch, that falls in a 10 second interval.~~ Parameters Parameter Description Default node-param rate ( integer duration ) sample rate","title":"Sample"},{"location":"nodes/sample.html#the-sample-node","text":"Samples the incoming points or batches. One point will be emitted every count ~~or duration~~ specified. Note: time based sampling is not supported with this version","title":"The sample node"},{"location":"nodes/sample.html#example","text":"| sample( 5 ) Keep every 5th data_point or data_batch. ~~| sample( 10s ) ~~ ~~Keep every point or batch, that falls in a 10 second interval.~~","title":"Example"},{"location":"nodes/sample.html#parameters","text":"Parameter Description Default node-param rate ( integer duration ) sample rate","title":"Parameters"},{"location":"nodes/set.html","text":"The set node Set fields and/or tags to a data_point or batch. Overwrites any existing fields or tags. Example | set() . fields ( 'id' , 'vs' , 'df' ) . field_values ( 'some_id' , 1 , '05.043' ) The above example will set the field id to the value 'some_id'. Accordingly vs will be set to 1, df will be set to '05.043'. Parameters Parameter Description Default fields( string_list ) list of fieldnames [] field_values( list ) list of values for the given fields (must have the same length as fieldnames) [] tags( string_list ) list of tagnames [] tag_values( list ) list of values for the given tags (must have the same length as tagnames) []","title":"Set"},{"location":"nodes/set.html#the-set-node","text":"Set fields and/or tags to a data_point or batch. Overwrites any existing fields or tags.","title":"The set node"},{"location":"nodes/set.html#example","text":"| set() . fields ( 'id' , 'vs' , 'df' ) . field_values ( 'some_id' , 1 , '05.043' ) The above example will set the field id to the value 'some_id'. Accordingly vs will be set to 1, df will be set to '05.043'.","title":"Example"},{"location":"nodes/set.html#parameters","text":"Parameter Description Default fields( string_list ) list of fieldnames [] field_values( list ) list of values for the given fields (must have the same length as fieldnames) [] tags( string_list ) list of tagnames [] tag_values( list ) list of values for the given tags (must have the same length as tagnames) []","title":"Parameters"},{"location":"nodes/shift.html","text":"The shift node The shift node shifts points and batches in time. This is useful for comparing batches or points from different times. Example | shift( 5m ) Shift all data points 5 minutes forward in time. | shift( - 10s ) Shift all data points 10 seconds backwards in time. Parameters Parameter Description Default [node] offset ( duration ) time offset","title":"Shift"},{"location":"nodes/shift.html#the-shift-node","text":"The shift node shifts points and batches in time. This is useful for comparing batches or points from different times.","title":"The shift node"},{"location":"nodes/shift.html#example","text":"| shift( 5m ) Shift all data points 5 minutes forward in time. | shift( - 10s ) Shift all data points 10 seconds backwards in time.","title":"Example"},{"location":"nodes/shift.html#parameters","text":"Parameter Description Default [node] offset ( duration ) time offset","title":"Parameters"},{"location":"nodes/state_count.html","text":"The state_count node Computes the number of consecutive points in a given state. The state is defined via a lambda expression. For each consecutive point for which the expression evaluates as true, the state count will be incremented. When a point evaluates to false, the state count is reset. The state count will be added as an additional int field to each point. If the expression evaluates to false, the value will be -1. If the expression generates an error during evaluation, the point is discarded and does not affect the state count. Example | state_count() . lambda ( lambda : \"val\" < 7 ) . as ( 'val_below_7' ) Counts the number of consecutive points which have the value of the val field below 7 . Parameters Parameter Description Default lambda( lambda ) state lambda expression as( string ) name for the added count field 'state_count'","title":"State count"},{"location":"nodes/state_count.html#the-state_count-node","text":"Computes the number of consecutive points in a given state. The state is defined via a lambda expression. For each consecutive point for which the expression evaluates as true, the state count will be incremented. When a point evaluates to false, the state count is reset. The state count will be added as an additional int field to each point. If the expression evaluates to false, the value will be -1. If the expression generates an error during evaluation, the point is discarded and does not affect the state count.","title":"The state_count node"},{"location":"nodes/state_count.html#example","text":"| state_count() . lambda ( lambda : \"val\" < 7 ) . as ( 'val_below_7' ) Counts the number of consecutive points which have the value of the val field below 7 .","title":"Example"},{"location":"nodes/state_count.html#parameters","text":"Parameter Description Default lambda( lambda ) state lambda expression as( string ) name for the added count field 'state_count'","title":"Parameters"},{"location":"nodes/state_duration.html","text":"The state_duration node Computes the duration of a given state. The state is defined via a lambda expression. For each consecutive point for which the lambda expression evaluates as true, the state duration will be incremented by the duration between points. When a point evaluates as false, the state duration is reset. The state duration will be added as an additional field to each point and it's unit is milliseconds . If the expression evaluates to false, the value will be -1. When the lambda expression generates an error during evaluation, the point is discarded and does not affect the state duration.. Example | state_duration() . lambda ( lambda : \"val\" < 7 ) Parameters Parameter Description Default lambda( lambda ) state lambda expression as( string ) name for the added duration field 'state_duration'","title":"State duration"},{"location":"nodes/state_duration.html#the-state_duration-node","text":"Computes the duration of a given state. The state is defined via a lambda expression. For each consecutive point for which the lambda expression evaluates as true, the state duration will be incremented by the duration between points. When a point evaluates as false, the state duration is reset. The state duration will be added as an additional field to each point and it's unit is milliseconds . If the expression evaluates to false, the value will be -1. When the lambda expression generates an error during evaluation, the point is discarded and does not affect the state duration..","title":"The state_duration node"},{"location":"nodes/state_duration.html#example","text":"| state_duration() . lambda ( lambda : \"val\" < 7 )","title":"Example"},{"location":"nodes/state_duration.html#parameters","text":"Parameter Description Default lambda( lambda ) state lambda expression as( string ) name for the added duration field 'state_duration'","title":"Parameters"},{"location":"nodes/state_sequence.html","text":"The state_sequence node This node takes a list of lambda expressions representing different states. It will emit values only after each state has evaluated as true in the given order and, for each step in the sequence within the corresponding timeout. A transition timeout must be defined for every state transition with the within parameter. If a timeout occurs at any point the sequence will be reset and started from the first expression again. Note that the sequence timeouts start after the first data_point has satisfied the first lambda expression. Therefore, if 3 lambda states are given, only 2 durations for the within parameter can be defined. With the strict parameter the sequence of states must be met exactly without any intermediary data_points coming in, that do not satisfy the current state expression. Normally this would not reset the sequence of evaluation, in this mode, it will. On a successful evaluation of the whole sequence, the node will simply output the last value, that completed the sequence. The state_sequence node can be used with one or many input nodes. Example in1 | state_sequence( in2 , in3 ) %% can use any number of nodes . states ( lambda : \"data.topic\" == 'in1' , %% state 1 lambda : \"data.topic\" == 'in2' , %% state 2 lambda : \"data.topic\" == 'in3' %% state 3 ) . within ( 25s , %% transition-time from state 1 to state 2 20s %% transition-time from state 2 to state 3 ) Parameters Parameter Description Default [node] nodes_in( node_list ) a list of node(chains) optional states ( lambda_list ) the states within( duration_list ) one timeout for every state-transition strict( is_set ) whether the state sequence must be transition exactly false (not set)","title":"State sequence"},{"location":"nodes/state_sequence.html#the-state_sequence-node","text":"This node takes a list of lambda expressions representing different states. It will emit values only after each state has evaluated as true in the given order and, for each step in the sequence within the corresponding timeout. A transition timeout must be defined for every state transition with the within parameter. If a timeout occurs at any point the sequence will be reset and started from the first expression again. Note that the sequence timeouts start after the first data_point has satisfied the first lambda expression. Therefore, if 3 lambda states are given, only 2 durations for the within parameter can be defined. With the strict parameter the sequence of states must be met exactly without any intermediary data_points coming in, that do not satisfy the current state expression. Normally this would not reset the sequence of evaluation, in this mode, it will. On a successful evaluation of the whole sequence, the node will simply output the last value, that completed the sequence. The state_sequence node can be used with one or many input nodes.","title":"The state_sequence node"},{"location":"nodes/state_sequence.html#example","text":"in1 | state_sequence( in2 , in3 ) %% can use any number of nodes . states ( lambda : \"data.topic\" == 'in1' , %% state 1 lambda : \"data.topic\" == 'in2' , %% state 2 lambda : \"data.topic\" == 'in3' %% state 3 ) . within ( 25s , %% transition-time from state 1 to state 2 20s %% transition-time from state 2 to state 3 )","title":"Example"},{"location":"nodes/state_sequence.html#parameters","text":"Parameter Description Default [node] nodes_in( node_list ) a list of node(chains) optional states ( lambda_list ) the states within( duration_list ) one timeout for every state-transition strict( is_set ) whether the state sequence must be transition exactly false (not set)","title":"Parameters"},{"location":"nodes/stats.html","text":"The stats node The stats node lets you compute statistical functions on data_points and data_batches. See nodes under statistics for details. Stats nodes produce a new stream, the incoming stream is not outputted. Parameters All statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Stats"},{"location":"nodes/stats.html#the-stats-node","text":"The stats node lets you compute statistical functions on data_points and data_batches. See nodes under statistics for details. Stats nodes produce a new stream, the incoming stream is not outputted.","title":"The stats node"},{"location":"nodes/stats.html#parameters","text":"All statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/tcp_receive.html","text":"The tcp_receive node This node connects to a tcp endpoint and awaits data in a special format, which is defined by the parser parameter. The parser will then try to convert the data to faxe's internal format and emit the result. At the moment tcp messages must start with a 2 byte header denoting the length of the following data. `Length_Header:16/integer, Data:{Length_Header}/binary` If the changed option is given, the node will only emit on changed values (crc32 checksum comparison). The tcp listener is protected against flooding with the {active, once} inet option. Example def parser = 'parser_robot_plc_v1' | tcp_recv () . ip ( '212.14.149.8' ) . port ( 9715 ) . parser ( parser ) . as ( 'data' ) Parameters Parameter Description Default ip( string ) ip or hostname for the tcp peer port( integer ) port number parser( string ) name of parser to use for data conversion, see table below as( string ) name of the field for parsed data changed( is_set ) whether to check for changed data false (not set) Available Parsers Parser name Description parser_robot_plc_v1 parses the special robotplc binary data format parser_conv_tracking_v1 parser for the conveyor tracking ascii-protocol","title":"Tcp receive"},{"location":"nodes/tcp_receive.html#the-tcp_receive-node","text":"This node connects to a tcp endpoint and awaits data in a special format, which is defined by the parser parameter. The parser will then try to convert the data to faxe's internal format and emit the result. At the moment tcp messages must start with a 2 byte header denoting the length of the following data. `Length_Header:16/integer, Data:{Length_Header}/binary` If the changed option is given, the node will only emit on changed values (crc32 checksum comparison). The tcp listener is protected against flooding with the {active, once} inet option.","title":"The tcp_receive node"},{"location":"nodes/tcp_receive.html#example","text":"def parser = 'parser_robot_plc_v1' | tcp_recv () . ip ( '212.14.149.8' ) . port ( 9715 ) . parser ( parser ) . as ( 'data' )","title":"Example"},{"location":"nodes/tcp_receive.html#parameters","text":"Parameter Description Default ip( string ) ip or hostname for the tcp peer port( integer ) port number parser( string ) name of parser to use for data conversion, see table below as( string ) name of the field for parsed data changed( is_set ) whether to check for changed data false (not set)","title":"Parameters"},{"location":"nodes/tcp_receive.html#available-parsers","text":"Parser name Description parser_robot_plc_v1 parses the special robotplc binary data format parser_conv_tracking_v1 parser for the conveyor tracking ascii-protocol","title":"Available Parsers"},{"location":"nodes/tcp_receive_line.html","text":"The tcp_receive_line node This node connects to a tcp endpoint and awaits data in a line separated special format, which is defined by the parser parameter. The parser will then try to convert the data to faxe's internal format and emit the result. At the moment the line separator is fixed to \\n . If the changed option is given, the node will only emit on changed values (crc32 checksum comparison). The tcp listener is protected against flooding with the {active, once} inet option. Example def parser = 'parser_conv_tracking_v1' | tcp_recv_line () . ip ( '212.14.149.3' ) . port ( 2004 ) . parser ( parser ) . as ( 'data' ) Parameters Parameter Description Default ip( string ) ip or hostname for the tcp peer port( integer ) port number parser( string ) name of parser to use for data conversion, see table below as( string ) name of the field for parsed data changed( is_set ) whether to check for changed data false (not set) min_length( integer) lines shorter than min_length bytes will be ignored 61 Available Parsers Parser name Description parser_robot_plc_v1 parses the special robotplc binary data format parser_conv_tracking_v1 parser for the conveyor tracking ascii-protocol","title":"Tcp receive line"},{"location":"nodes/tcp_receive_line.html#the-tcp_receive_line-node","text":"This node connects to a tcp endpoint and awaits data in a line separated special format, which is defined by the parser parameter. The parser will then try to convert the data to faxe's internal format and emit the result. At the moment the line separator is fixed to \\n . If the changed option is given, the node will only emit on changed values (crc32 checksum comparison). The tcp listener is protected against flooding with the {active, once} inet option.","title":"The tcp_receive_line node"},{"location":"nodes/tcp_receive_line.html#example","text":"def parser = 'parser_conv_tracking_v1' | tcp_recv_line () . ip ( '212.14.149.3' ) . port ( 2004 ) . parser ( parser ) . as ( 'data' )","title":"Example"},{"location":"nodes/tcp_receive_line.html#parameters","text":"Parameter Description Default ip( string ) ip or hostname for the tcp peer port( integer ) port number parser( string ) name of parser to use for data conversion, see table below as( string ) name of the field for parsed data changed( is_set ) whether to check for changed data false (not set) min_length( integer) lines shorter than min_length bytes will be ignored 61","title":"Parameters"},{"location":"nodes/tcp_receive_line.html#available-parsers","text":"Parser name Description parser_robot_plc_v1 parses the special robotplc binary data format parser_conv_tracking_v1 parser for the conveyor tracking ascii-protocol","title":"Available Parsers"},{"location":"nodes/time_diff.html","text":"The time_diff node The time_diff node adds a field to the current data-item containing the difference between the timestamps of the consecutive items. Note that the difference in time will be calculated from the data-points timestamp fields and does not reflect the difference in time points coming into the node. For the other behaviour see time_elapsed . The unit for output values is milliseconds. Example | time_diff() . as ( 'time_diff' ) Parameters Parameter Description Default as( string ) name of the field for parsed data 'timediff'","title":"Time diff"},{"location":"nodes/time_diff.html#the-time_diff-node","text":"The time_diff node adds a field to the current data-item containing the difference between the timestamps of the consecutive items. Note that the difference in time will be calculated from the data-points timestamp fields and does not reflect the difference in time points coming into the node. For the other behaviour see time_elapsed . The unit for output values is milliseconds.","title":"The time_diff node"},{"location":"nodes/time_diff.html#example","text":"| time_diff() . as ( 'time_diff' )","title":"Example"},{"location":"nodes/time_diff.html#parameters","text":"Parameter Description Default as( string ) name of the field for parsed data 'timediff'","title":"Parameters"},{"location":"nodes/time_elapsed.html","text":"The time_elapsed node The time_elapsed node adds a field to the current data-item containing the difference in arrival time of consecutive items. See the time_diff node . The unit for output values is milliseconds. Example | time_elapsed() . as ( 'time_dur' ) Parameters Parameter Description Default as( string ) name of the field for parsed data 'elapsed'","title":"Time elapsed"},{"location":"nodes/time_elapsed.html#the-time_elapsed-node","text":"The time_elapsed node adds a field to the current data-item containing the difference in arrival time of consecutive items. See the time_diff node . The unit for output values is milliseconds.","title":"The time_elapsed node"},{"location":"nodes/time_elapsed.html#example","text":"| time_elapsed() . as ( 'time_dur' )","title":"Example"},{"location":"nodes/time_elapsed.html#parameters","text":"Parameter Description Default as( string ) name of the field for parsed data 'elapsed'","title":"Parameters"},{"location":"nodes/triggered_timeout.html","text":"The triggered_timeout node Emits a point, if there is no message coming in for the given amount of time. A timeout will be started on an explicit trigger: * When a lambda expression is given for parameter timeout_trigger , this expression must evaluate as true to start (and after a timeout has occurred to restart) a timeout. If no lambda expression is given for the timeout_trigger , the trigger is any data_point coming in on port 1, the so called trigger_port . A new trigger does not restart a running timeout. After a timeout occurred, the node waits for a new trigger to come in before it starts a new timeout. After a timeout is started the node waits for data coming in, that either does not satisfy the trigger expression(when a lambda expression is given for the timeout_trigger parameter) or is coming in on any port except the trigger_port (port 1). Data for the outgoing data-point can be defined with the fields and field_values parameters. This node can have any number of input-nodes. Example def timeout = 30s % ... in1 | triggered_timeout( in2 ) . timeout ( timeout ) . timeout_trigger ( lambda : \"data.topic\" == 'in1' ) def condition_reason = 'oh no !!' robot_state | triggered_timeout( or derlog ) . timeout ( timeout ) . fields ( 'combined.condition.name' , 'combined.condition_reason' , 'combined.condition.id' ) . field_values ( 'ERROR' , condition_reason , 2 ) %.cancel_fields('combined.condition.name', 'combined.condition_reason', 'combined.condition.id') %.cancel_field_values('OK', '', 0) Parameters Parameter Description Default timeout( duration ) timeout_trigger( lambda ) lambda expression which triggers the timeout optional fields ( string_list ) paths for the output fields optional field_values( list ) values for the output fields optional","title":"Triggered timeout"},{"location":"nodes/triggered_timeout.html#the-triggered_timeout-node","text":"Emits a point, if there is no message coming in for the given amount of time. A timeout will be started on an explicit trigger: * When a lambda expression is given for parameter timeout_trigger , this expression must evaluate as true to start (and after a timeout has occurred to restart) a timeout. If no lambda expression is given for the timeout_trigger , the trigger is any data_point coming in on port 1, the so called trigger_port . A new trigger does not restart a running timeout. After a timeout occurred, the node waits for a new trigger to come in before it starts a new timeout. After a timeout is started the node waits for data coming in, that either does not satisfy the trigger expression(when a lambda expression is given for the timeout_trigger parameter) or is coming in on any port except the trigger_port (port 1). Data for the outgoing data-point can be defined with the fields and field_values parameters. This node can have any number of input-nodes.","title":"The triggered_timeout node"},{"location":"nodes/triggered_timeout.html#example","text":"def timeout = 30s % ... in1 | triggered_timeout( in2 ) . timeout ( timeout ) . timeout_trigger ( lambda : \"data.topic\" == 'in1' ) def condition_reason = 'oh no !!' robot_state | triggered_timeout( or derlog ) . timeout ( timeout ) . fields ( 'combined.condition.name' , 'combined.condition_reason' , 'combined.condition.id' ) . field_values ( 'ERROR' , condition_reason , 2 ) %.cancel_fields('combined.condition.name', 'combined.condition_reason', 'combined.condition.id') %.cancel_field_values('OK', '', 0)","title":"Example"},{"location":"nodes/triggered_timeout.html#parameters","text":"Parameter Description Default timeout( duration ) timeout_trigger( lambda ) lambda expression which triggers the timeout optional fields ( string_list ) paths for the output fields optional field_values( list ) values for the output fields optional","title":"Parameters"},{"location":"nodes/union.html","text":"The union node Union of multiple streams. The union node takes the union of all of its parents as a simple pass through. Data points received from each parent are passed onto children nodes without modification. Example in1 | union( in2 , in3 ) The union of 3 nodes (chain expressions) Parameters Parameter Description Default [node] nodes_in( node_list ) optional","title":"Union"},{"location":"nodes/union.html#the-union-node","text":"Union of multiple streams. The union node takes the union of all of its parents as a simple pass through. Data points received from each parent are passed onto children nodes without modification.","title":"The union node"},{"location":"nodes/union.html#example","text":"in1 | union( in2 , in3 ) The union of 3 nodes (chain expressions)","title":"Example"},{"location":"nodes/union.html#parameters","text":"Parameter Description Default [node] nodes_in( node_list ) optional","title":"Parameters"},{"location":"nodes/value_emitter.html","text":"The value_emitter node This node is for debugging purposes. It periodically emits random values. Example | value_emitter() . every ( 1s ) . type ( point ) Emit a data_point with a random value in field val every second. Parameters Parameter Description Default every( duration ) emit interval 5s jitter( duration ) add time jitter to the values produced 0ms type( atom ) emit point or batch batch fields( string_list ) what fields to emit ['val'] format( atom ) the format of the fields emitted flat/ejson flat align( is_set ) align the time to the every param false (not set)","title":"Value emitter"},{"location":"nodes/value_emitter.html#the-value_emitter-node","text":"This node is for debugging purposes. It periodically emits random values.","title":"The value_emitter node"},{"location":"nodes/value_emitter.html#example","text":"| value_emitter() . every ( 1s ) . type ( point ) Emit a data_point with a random value in field val every second.","title":"Example"},{"location":"nodes/value_emitter.html#parameters","text":"Parameter Description Default every( duration ) emit interval 5s jitter( duration ) add time jitter to the values produced 0ms type( atom ) emit point or batch batch fields( string_list ) what fields to emit ['val'] format( atom ) the format of the fields emitted flat/ejson flat align( is_set ) align the time to the every param false (not set)","title":"Parameters"},{"location":"nodes/where.html","text":"The where node Filter points and batches with a lambda expression, which returns a boolean value. Data-items for which the lambda expression evaluates as false will be discarded. Example | where( lambda : hour ( \"ts\" ) < 18 AND hour ( \"ts\" ) > 8 ) Filters points who's timestamp is not between 09:00 and 18:00. Parameters Parameter Description Default [node] lambda( lambda ) The lambda filter expression","title":"Where"},{"location":"nodes/where.html#the-where-node","text":"Filter points and batches with a lambda expression, which returns a boolean value. Data-items for which the lambda expression evaluates as false will be discarded.","title":"The where node"},{"location":"nodes/where.html#example","text":"| where( lambda : hour ( \"ts\" ) < 18 AND hour ( \"ts\" ) > 8 ) Filters points who's timestamp is not between 09:00 and 18:00.","title":"Example"},{"location":"nodes/where.html#parameters","text":"Parameter Description Default [node] lambda( lambda ) The lambda filter expression","title":"Parameters"},{"location":"nodes/win_clock.html","text":"The win_clock node A window node is for batching data_points. This window-type has wall-clock timing, timestamps contained in incoming events are not relevant here. When the align option is true, window boundaries are aligned according to the every option, this means when every is 5s and an event comes into the window at time 15:03:27, this event will be member of the window that starts at 15:03:25, otherwise the window would start at 15:03:27. By default, the boundries are defined relative to the first data point the window node receives. With fill_period given, the window will not emit before \"period\" time has elapsed (for the first time). This only applies if the period is greater than the every value. Example | win_clock() . every ( 5s ) . period ( 15s ) . fill_period () . align () The window will emit every 5 seconds, but only after initially 15 seconds have passed (due to fill_period ), it has its boundaries aligned to 5 second intervals. Parameters Parameter Description Default period( duration ) Window length defaults to every every( duration ) Output window contents every align( is_set ) Align the window boundaries false (not set) fill_period( is_set ) Window output only when period time has elapsed false (not set)","title":"Win clock"},{"location":"nodes/win_clock.html#the-win_clock-node","text":"A window node is for batching data_points. This window-type has wall-clock timing, timestamps contained in incoming events are not relevant here. When the align option is true, window boundaries are aligned according to the every option, this means when every is 5s and an event comes into the window at time 15:03:27, this event will be member of the window that starts at 15:03:25, otherwise the window would start at 15:03:27. By default, the boundries are defined relative to the first data point the window node receives. With fill_period given, the window will not emit before \"period\" time has elapsed (for the first time). This only applies if the period is greater than the every value.","title":"The win_clock node"},{"location":"nodes/win_clock.html#example","text":"| win_clock() . every ( 5s ) . period ( 15s ) . fill_period () . align () The window will emit every 5 seconds, but only after initially 15 seconds have passed (due to fill_period ), it has its boundaries aligned to 5 second intervals.","title":"Example"},{"location":"nodes/win_clock.html#parameters","text":"Parameter Description Default period( duration ) Window length defaults to every every( duration ) Output window contents every align( is_set ) Align the window boundaries false (not set) fill_period( is_set ) Window output only when period time has elapsed false (not set)","title":"Parameters"},{"location":"nodes/win_event.html","text":"The win_event node A window node is for batching data_points. This window holds period number of data_points and emits every every incoming point. With fill_period given, the window will only emit when it is filled with period points. This only applies if the period is greater than the every value. Examples | win_event() . every ( 5 ) . period ( 15 ) . fill_period () The window will emit it's contents every 5 incoming points, but only after the window is filled with 15 points. | win_event() . every ( 5 ) . period ( 15 ) The window will emit it's contents every 5 incoming points. On first emit 5 points will be outputted, on the second emit 10 points will be emitted. From the third emit onwards, the window will output 15 points. Starting with the 4th emit, the window will output 15 data_points - with 10 old and 5 new points (Tumbling window). Parameters Parameter Description Default period( integer ) Window length, number of points defaults to every every( integer ) Output window contents every n incoming points fill_period( is_set ) Output only when window is filled false (not set)","title":"Win event"},{"location":"nodes/win_event.html#the-win_event-node","text":"A window node is for batching data_points. This window holds period number of data_points and emits every every incoming point. With fill_period given, the window will only emit when it is filled with period points. This only applies if the period is greater than the every value.","title":"The win_event node"},{"location":"nodes/win_event.html#examples","text":"| win_event() . every ( 5 ) . period ( 15 ) . fill_period () The window will emit it's contents every 5 incoming points, but only after the window is filled with 15 points. | win_event() . every ( 5 ) . period ( 15 ) The window will emit it's contents every 5 incoming points. On first emit 5 points will be outputted, on the second emit 10 points will be emitted. From the third emit onwards, the window will output 15 points. Starting with the 4th emit, the window will output 15 data_points - with 10 old and 5 new points (Tumbling window).","title":"Examples"},{"location":"nodes/win_event.html#parameters","text":"Parameter Description Default period( integer ) Window length, number of points defaults to every every( integer ) Output window contents every n incoming points fill_period( is_set ) Output only when window is filled false (not set)","title":"Parameters"},{"location":"nodes/win_time.html","text":"The win_time node A window node is for batching data_points. This window refers it's timing to the timestamp contained in the incoming data-items. With fill_period given, the window will not emit before \"period\" time has elapsed (for the first time). Note that, since this window type does not rely on wall clock, but on the points timestamps, it is possible that no data is emitted, if there are no new points coming in. Example | win_time() . every ( 5s ) . period ( 15s ) The window will emit it's contents every 5 seconds. | win_time() . every ( 1m ) Period is 1 minute here (period defaults to every) Parameters Parameter Description Default period( duration ) Window length defaults to every every( duration ) Output window contents every fill_period( is_set ) Window output only when period time has accumulated false (not set)","title":"Win time"},{"location":"nodes/win_time.html#the-win_time-node","text":"A window node is for batching data_points. This window refers it's timing to the timestamp contained in the incoming data-items. With fill_period given, the window will not emit before \"period\" time has elapsed (for the first time). Note that, since this window type does not rely on wall clock, but on the points timestamps, it is possible that no data is emitted, if there are no new points coming in.","title":"The win_time node"},{"location":"nodes/win_time.html#example","text":"| win_time() . every ( 5s ) . period ( 15s ) The window will emit it's contents every 5 seconds. | win_time() . every ( 1m ) Period is 1 minute here (period defaults to every)","title":"Example"},{"location":"nodes/win_time.html#parameters","text":"Parameter Description Default period( duration ) Window length defaults to every every( duration ) Output window contents every fill_period( is_set ) Window output only when period time has accumulated false (not set)","title":"Parameters"},{"location":"nodes/statistics/avg.html","text":"The avg node Compute the average. See the stats node Example | avg () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Avg"},{"location":"nodes/statistics/avg.html#the-avg-node","text":"Compute the average. See the stats node","title":"The avg node"},{"location":"nodes/statistics/avg.html#example","text":"| avg () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/avg.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/bottom.html","text":"The sum node Select the bottom num points for field. See the stats node Example | bottom () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node num( integer ) number of points to select 1","title":"Bottom"},{"location":"nodes/statistics/bottom.html#the-sum-node","text":"Select the bottom num points for field. See the stats node","title":"The sum node"},{"location":"nodes/statistics/bottom.html#example","text":"| bottom () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/bottom.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node num( integer ) number of points to select 1","title":"Parameters"},{"location":"nodes/statistics/count.html","text":"The count node Count the number of points. See the stats node Example | count () . field ( 'over_ts' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Count"},{"location":"nodes/statistics/count.html#the-count-node","text":"Count the number of points. See the stats node","title":"The count node"},{"location":"nodes/statistics/count.html#example","text":"| count () . field ( 'over_ts' )","title":"Example"},{"location":"nodes/statistics/count.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/distinct.html","text":"The distinct node Select unique values. See the stats node Example | distinct () . field ( 'status' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Distinct"},{"location":"nodes/statistics/distinct.html#the-distinct-node","text":"Select unique values. See the stats node","title":"The distinct node"},{"location":"nodes/statistics/distinct.html#example","text":"| distinct () . field ( 'status' )","title":"Example"},{"location":"nodes/statistics/distinct.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/elapsed.html","text":"The elapsed node Compute the elapsed time between points. See the stats node Example | elapsed () . field ( 'trigger' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Elapsed"},{"location":"nodes/statistics/elapsed.html#the-elapsed-node","text":"Compute the elapsed time between points. See the stats node","title":"The elapsed node"},{"location":"nodes/statistics/elapsed.html#example","text":"| elapsed () . field ( 'trigger' )","title":"Example"},{"location":"nodes/statistics/elapsed.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/first.html","text":"The first node Select the first that means the oldest point. See the stats node Example | first () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"First"},{"location":"nodes/statistics/first.html#the-first-node","text":"Select the first that means the oldest point. See the stats node","title":"The first node"},{"location":"nodes/statistics/first.html#example","text":"| first () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/first.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/geometric_mean.html","text":"The geometric_mean node Compute the geometric_mean. See the stats node Example | geometric_mean () . field ( 'pressure' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Geometric mean"},{"location":"nodes/statistics/geometric_mean.html#the-geometric_mean-node","text":"Compute the geometric_mean. See the stats node","title":"The geometric_mean node"},{"location":"nodes/statistics/geometric_mean.html#example","text":"| geometric_mean () . field ( 'pressure' )","title":"Example"},{"location":"nodes/statistics/geometric_mean.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/kurtosis.html","text":"The kurtosis node Compute the kurtosis of data. See the stats node Example | kurtosis () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Kurtosis"},{"location":"nodes/statistics/kurtosis.html#the-kurtosis-node","text":"Compute the kurtosis of data. See the stats node","title":"The kurtosis node"},{"location":"nodes/statistics/kurtosis.html#example","text":"| kurtosis () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/kurtosis.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/last.html","text":"The last node Select the last, that means the newest point. See the stats node Example | last () . field ( 'chair' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Last"},{"location":"nodes/statistics/last.html#the-last-node","text":"Select the last, that means the newest point. See the stats node","title":"The last node"},{"location":"nodes/statistics/last.html#example","text":"| last () . field ( 'chair' )","title":"Example"},{"location":"nodes/statistics/last.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/max.html","text":"The max node Compute the maximum value. See the stats node Example | max () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Max"},{"location":"nodes/statistics/max.html#the-max-node","text":"Compute the maximum value. See the stats node","title":"The max node"},{"location":"nodes/statistics/max.html#example","text":"| max () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/max.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/mean.html","text":"The mean node Compute the mean of data. See the stats node Example | mean () . field ( 'current' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Mean"},{"location":"nodes/statistics/mean.html#the-mean-node","text":"Compute the mean of data. See the stats node","title":"The mean node"},{"location":"nodes/statistics/mean.html#example","text":"| mean () . field ( 'current' )","title":"Example"},{"location":"nodes/statistics/mean.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/median.html","text":"The median node Compute the median of data. See the stats node Example | median () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Median"},{"location":"nodes/statistics/median.html#the-median-node","text":"Compute the median of data. See the stats node","title":"The median node"},{"location":"nodes/statistics/median.html#example","text":"| median () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/median.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/min.html","text":"The min node Compute the minimum of data. See the stats node Example | min () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Min"},{"location":"nodes/statistics/min.html#the-min-node","text":"Compute the minimum of data. See the stats node","title":"The min node"},{"location":"nodes/statistics/min.html#example","text":"| min () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/min.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/percentile.html","text":"The percentile node Select a point at the given percentile. This is a selector function, no interpolation between points is performed. See the stats node Example | percentile () . perc ( 95 ) . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node perc ( integer ) select percentile 95","title":"Percentile"},{"location":"nodes/statistics/percentile.html#the-percentile-node","text":"Select a point at the given percentile. This is a selector function, no interpolation between points is performed. See the stats node","title":"The percentile node"},{"location":"nodes/statistics/percentile.html#example","text":"| percentile () . perc ( 95 ) . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/percentile.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node perc ( integer ) select percentile 95","title":"Parameters"},{"location":"nodes/statistics/stddev.html","text":"The stddev node Compute the standard deviation of the data. See the stats node Example | stddev () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Stddev"},{"location":"nodes/statistics/stddev.html#the-stddev-node","text":"Compute the standard deviation of the data. See the stats node","title":"The stddev node"},{"location":"nodes/statistics/stddev.html#example","text":"| stddev () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/stddev.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/sum.html","text":"The sum node Compute the sum of data. See the stats node Example | sum () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Sum"},{"location":"nodes/statistics/sum.html#the-sum-node","text":"Compute the sum of data. See the stats node","title":"The sum node"},{"location":"nodes/statistics/sum.html#example","text":"| sum () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/sum.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"},{"location":"nodes/statistics/top.html","text":"The top node Select the top num points. See the stats node Example | top () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node num( integer ) number of points to select 1","title":"Top"},{"location":"nodes/statistics/top.html#the-top-node","text":"Select the top num points. See the stats node","title":"The top node"},{"location":"nodes/statistics/top.html#example","text":"| top () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/top.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node num( integer ) number of points to select 1","title":"Parameters"},{"location":"nodes/statistics/variance.html","text":"The variance node Compute the data's variance. See the stats node Example | variance () . field ( 'temperature' ) Parameters all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Variance"},{"location":"nodes/statistics/variance.html#the-variance-node","text":"Compute the data's variance. See the stats node","title":"The variance node"},{"location":"nodes/statistics/variance.html#example","text":"| variance () . field ( 'temperature' )","title":"Example"},{"location":"nodes/statistics/variance.html#parameters","text":"all statistics nodes have the following parameters Parameter Description Default field( string ) name of the field used for computation as( string ) name for the field for output values defaults to the name of the stats-node","title":"Parameters"}]}